{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CenterResnet Starter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am very new to these concepts so I am trying out by changing this amazing and probably only 3D model related awesome public kernel by Ruslan\n",
    "https://www.kaggle.com/hocop1/centernet-baseline\n",
    "\n",
    "Most of the codes are loaned from there . There are other codes that I took from OFT implementation github . But I dont know what is OFT , so I have not yet implemented it . \n",
    "\n",
    "My current score is not from this kernel( as there are some errors in this kernel) , but from some simple architecture modification of the original public kernel. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "from tqdm.auto import tqdm as tq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "PATH = '../input/pku-autonomous-driving/'\n",
    "os.listdir(PATH)\n",
    "\n",
    "## Constants\n",
    "SWITCH_LOSS_EPOCH = 4\n",
    "\n",
    "train = pd.read_csv(PATH + 'train.csv')\n",
    "test = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "\n",
    "# From camera.zip\n",
    "camera_matrix = np.array([[2304.5479, 0,  1686.2379],\n",
    "                          [0, 2305.8757, 1354.9849],\n",
    "                          [0, 0, 1]], dtype=np.float32)\n",
    "camera_matrix_inv = np.linalg.inv(camera_matrix)\n",
    "\n",
    "def imread(path, fast_mode=False):\n",
    "    img = cv2.imread(path)\n",
    "    if not fast_mode and img is not None and len(img.shape) == 3:\n",
    "        img = np.array(img[:, :, ::-1])\n",
    "    return img\n",
    "\n",
    "img = imread(PATH + 'train_images/ID_8a6e65317' + '.jpg')\n",
    "IMG_SHAPE = img.shape\n",
    "\n",
    "def str2coords(s, names=['id', 'yaw', 'pitch', 'roll', 'x', 'y', 'z']):\n",
    "    '''\n",
    "    Input:\n",
    "        s: PredictionString (e.g. from train dataframe)\n",
    "        names: array of what to extract from the string\n",
    "    Output:\n",
    "        list of dicts with keys from `names`\n",
    "    '''\n",
    "    coords = []\n",
    "    for l in np.array(s.split()).reshape([-1, 7]):\n",
    "        coords.append(dict(zip(names, l.astype('float'))))\n",
    "        if 'id' in coords[-1]:\n",
    "            coords[-1]['id'] = int(coords[-1]['id'])\n",
    "    return coords\n",
    "\n",
    "def rotate(x, angle):\n",
    "    x = x + angle\n",
    "    x = x - (x + np.pi) // (2 * np.pi) * 2 * np.pi\n",
    "    return x\n",
    "\n",
    "def get_img_coords(s):\n",
    "    '''\n",
    "    Input is a PredictionString (e.g. from train dataframe)\n",
    "    Output is two arrays:\n",
    "        xs: x coordinates in the image\n",
    "        ys: y coordinates in the image\n",
    "    '''\n",
    "    coords = str2coords(s)\n",
    "    xs = [c['x'] for c in coords]\n",
    "    ys = [c['y'] for c in coords]\n",
    "    zs = [c['z'] for c in coords]\n",
    "    P = np.array(list(zip(xs, ys, zs))).T\n",
    "    img_p = np.dot(camera_matrix, P).T\n",
    "    img_p[:, 0] /= img_p[:, 2]\n",
    "    img_p[:, 1] /= img_p[:, 2]\n",
    "    img_xs = img_p[:, 0]\n",
    "    img_ys = img_p[:, 1]\n",
    "    img_zs = img_p[:, 2] # z = Distance from the camera\n",
    "    return img_xs, img_ys\n",
    "\n",
    "from math import sin, cos\n",
    "\n",
    "# convert euler angle to rotation matrix\n",
    "def euler_to_Rot(yaw, pitch, roll):\n",
    "    Y = np.array([[cos(yaw), 0, sin(yaw)],\n",
    "                  [0, 1, 0],\n",
    "                  [-sin(yaw), 0, cos(yaw)]])\n",
    "    P = np.array([[1, 0, 0],\n",
    "                  [0, cos(pitch), -sin(pitch)],\n",
    "                  [0, sin(pitch), cos(pitch)]])\n",
    "    R = np.array([[cos(roll), -sin(roll), 0],\n",
    "                  [sin(roll), cos(roll), 0],\n",
    "                  [0, 0, 1]])\n",
    "    return np.dot(Y, np.dot(P, R))\n",
    "\n",
    "def draw_line(image, points):\n",
    "    color = (255, 0, 0)\n",
    "    cv2.line(image, tuple(points[0][:2]), tuple(points[3][:2]), color, 16)\n",
    "    cv2.line(image, tuple(points[0][:2]), tuple(points[1][:2]), color, 16)\n",
    "    cv2.line(image, tuple(points[1][:2]), tuple(points[2][:2]), color, 16)\n",
    "    cv2.line(image, tuple(points[2][:2]), tuple(points[3][:2]), color, 16)\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_points(image, points):\n",
    "    for (p_x, p_y, p_z) in points:\n",
    "        cv2.circle(image, (p_x, p_y), int(1000 / p_z), (0, 255, 0), -1)\n",
    "#         if p_x > image.shape[1] or p_y > image.shape[0]:\n",
    "#             print('Point', p_x, p_y, 'is out of image with shape', image.shape)\n",
    "    return image\n",
    "\n",
    "def visualize(img, coords):\n",
    "    # You will also need functions from the previous cells\n",
    "    x_l = 1.02\n",
    "    y_l = 0.80\n",
    "    z_l = 2.31\n",
    "    \n",
    "    img = img.copy()\n",
    "    for point in coords:\n",
    "        # Get values\n",
    "        x, y, z = point['x'], point['y'], point['z']\n",
    "        yaw, pitch, roll = -point['pitch'], -point['yaw'], -point['roll']\n",
    "        # Math\n",
    "        Rt = np.eye(4)\n",
    "        t = np.array([x, y, z])\n",
    "        Rt[:3, 3] = t\n",
    "        Rt[:3, :3] = euler_to_Rot(yaw, pitch, roll).T\n",
    "        Rt = Rt[:3, :]\n",
    "        P = np.array([[x_l, -y_l, -z_l, 1],\n",
    "                      [x_l, -y_l, z_l, 1],\n",
    "                      [-x_l, -y_l, z_l, 1],\n",
    "                      [-x_l, -y_l, -z_l, 1],\n",
    "                      [0, 0, 0, 1]]).T\n",
    "        img_cor_points = np.dot(camera_matrix, np.dot(Rt, P))\n",
    "        img_cor_points = img_cor_points.T\n",
    "        img_cor_points[:, 0] /= img_cor_points[:, 2]\n",
    "        img_cor_points[:, 1] /= img_cor_points[:, 2]\n",
    "        img_cor_points = img_cor_points.astype(int)\n",
    "        # Drawing\n",
    "        img = draw_line(img, img_cor_points)\n",
    "        img = draw_points(img, img_cor_points[-1:])\n",
    "    \n",
    "    return img\n",
    "\n",
    "IMG_WIDTH = 2048\n",
    "IMG_HEIGHT = IMG_WIDTH // 4\n",
    "MODEL_SCALE = 8\n",
    "\n",
    "def _regr_preprocess(regr_dict, flip=False):\n",
    "    if flip:\n",
    "        for k in ['x', 'pitch', 'roll']:\n",
    "            regr_dict[k] = -regr_dict[k]\n",
    "    for name in ['x', 'y', 'z']:\n",
    "        regr_dict[name] = regr_dict[name] / 100\n",
    "    regr_dict['roll'] = rotate(regr_dict['roll'], np.pi)\n",
    "    regr_dict['pitch_sin'] = sin(regr_dict['pitch'])\n",
    "    regr_dict['pitch_cos'] = cos(regr_dict['pitch'])\n",
    "    regr_dict.pop('pitch')\n",
    "    regr_dict.pop('id')\n",
    "    return regr_dict\n",
    "\n",
    "\n",
    "def _regr_back(regr_dict):\n",
    "    for name in ['x', 'y', 'z']:\n",
    "        regr_dict[name] = regr_dict[name] * 100\n",
    "    regr_dict['roll'] = rotate(regr_dict['roll'], -np.pi)\n",
    "    \n",
    "    pitch_sin = regr_dict['pitch_sin'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
    "    pitch_cos = regr_dict['pitch_cos'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
    "    regr_dict['pitch'] = np.arccos(pitch_cos) * np.sign(pitch_sin)\n",
    "    return regr_dict\n",
    "\n",
    "def preprocess_image(img, flip=False):\n",
    "    img = img[img.shape[0] // 2:]\n",
    "    bg = np.ones_like(img) * img.mean(1, keepdims=True).astype(img.dtype)\n",
    "    bg = bg[:, :img.shape[1] // 6]\n",
    "    img = np.concatenate([bg, img, bg], 1)\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    if flip:\n",
    "        img = img[:,::-1]\n",
    "    return (img / 255).astype('float32')\n",
    "\n",
    "\n",
    "def get_mask_and_regr(img, labels, flip=False):\n",
    "    mask = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n",
    "    regr_names = ['x', 'y', 'z', 'yaw', 'pitch', 'roll']\n",
    "    regr = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 7], dtype='float32')\n",
    "    coords = str2coords(labels)\n",
    "    xs, ys = get_img_coords(labels)\n",
    "    for x, y, regr_dict in zip(xs, ys, coords):\n",
    "        x, y = y, x\n",
    "        x = (x - img.shape[0] // 2) * IMG_HEIGHT / (img.shape[0] // 2) / MODEL_SCALE\n",
    "        x = np.round(x).astype('int')\n",
    "        y = (y + img.shape[1] // 6) * IMG_WIDTH / (img.shape[1] * 4/3) / MODEL_SCALE\n",
    "        y = np.round(y).astype('int')\n",
    "        if x >= 0 and x < IMG_HEIGHT // MODEL_SCALE and y >= 0 and y < IMG_WIDTH // MODEL_SCALE:\n",
    "            mask[x, y] = 1\n",
    "            regr_dict = _regr_preprocess(regr_dict, flip)\n",
    "            regr[x, y] = [regr_dict[n] for n in sorted(regr_dict)]\n",
    "    if flip:\n",
    "        mask = np.array(mask[:,::-1])\n",
    "        regr = np.array(regr[:,::-1])\n",
    "    return mask, regr\n",
    "\n",
    "class CarDataset(Dataset):\n",
    "    \"\"\"Car dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, root_dir, training=True, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Get image name\n",
    "        idx, labels = self.df.values[idx]\n",
    "        img_name = self.root_dir.format(idx)\n",
    "        \n",
    "        # Augmentation\n",
    "        if self.training:\n",
    "            flip = np.random.randint(10) == 1\n",
    "        \n",
    "        # Read image\n",
    "        img0 = imread(img_name, True)\n",
    "        img = preprocess_image(img0, flip)\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "        \n",
    "        # Get mask and regression maps\n",
    "        if self.training:\n",
    "            mask, regr = get_mask_and_regr(img0, labels, flip)\n",
    "            regr = np.rollaxis(regr, 2, 0)\n",
    "        else:\n",
    "            mask, regr = 0, 0\n",
    "        \n",
    "        return [img, mask, regr]\n",
    "    \n",
    "train_images_dir = PATH + 'train_images/{}.jpg'\n",
    "test_images_dir = PATH + 'test_images/{}.jpg'\n",
    "\n",
    "df_train, df_dev = train_test_split(train, test_size=0.01, random_state=42)\n",
    "df_test = test\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "        iaa.AddElementwise((-20, 20)),\n",
    "        #iaa.ContrastNormalization((0.75, 1.5)),\n",
    "        iaa.LinearContrast((0.4, 1.6), per_channel=True),    \n",
    "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    ])\n",
    "      \n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        return self.aug.augment_image(img)\n",
    "\n",
    "transforms = ImgAugTransform()\n",
    "\n",
    "train_dataset = CarDataset(df_train, train_images_dir, transform = transforms)\n",
    "dev_dataset = CarDataset(df_dev, train_images_dir)\n",
    "test_dataset = CarDataset(df_test, test_images_dir)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Create data generators - they will produce batches\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from dlav0 import get_pose_net as get_dlav0\n",
    "\n",
    "_model_factory = {\n",
    "  #'res': get_pose_net, # default Resnet with deconv\n",
    "  'dlav0': get_dlav0, # default DLAup\n",
    "  #'dla': get_dla_dcn,\n",
    "  #'resdcn': get_pose_net_dcn,\n",
    "  #'hourglass': get_large_hourglass_net,\n",
    "}\n",
    "\n",
    "def create_model(arch, heads, head_conv):\n",
    "    num_layers = int(arch[arch.find('_') + 1:]) if '_' in arch else 0\n",
    "    arch = arch[:arch.find('_')] if '_' in arch else arch\n",
    "    arch = 'dlav0'\n",
    "    get_model = _model_factory[arch]\n",
    "    model = get_model(num_layers=num_layers, heads=heads, head_conv=head_conv)\n",
    "    return model\n",
    "\n",
    "model = create_model('dla_34', {'hm': 1, 'reg' : 7} , 256)\n",
    "\n",
    "# Gets the GPU if there is one, otherwise the cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "#model = CentResnet(8).to(device)\n",
    "model.cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=8 * len(train_loader), gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_radius(det_size, min_overlap=0.7):\n",
    "    height, width = det_size\n",
    "\n",
    "    a1  = 1\n",
    "    b1  = (height + width)\n",
    "    c1  = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "    sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "    r1  = (b1 + sq1) / 2\n",
    "\n",
    "    a2  = 4\n",
    "    b2  = 2 * (height + width)\n",
    "    c2  = (1 - min_overlap) * width * height\n",
    "    sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "    r2  = (b2 + sq2) / 2\n",
    "\n",
    "    a3  = 4 * min_overlap\n",
    "    b3  = -2 * min_overlap * (height + width)\n",
    "    c3  = (min_overlap - 1) * width * height\n",
    "    sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "    r3  = (b3 + sq3) / 2\n",
    "    return min(r1, r2, r3)\n",
    "\n",
    "def gaussian2D(shape, sigma=1):\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m+1,-n:n+1]\n",
    "\n",
    "    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    return h\n",
    "\n",
    "def draw_msra_gaussian(heatmap, center, sigma):\n",
    "    tmp_size = sigma * 3\n",
    "    mu_x = int(center[0] + 0.5)\n",
    "    mu_y = int(center[1] + 0.5)\n",
    "    w, h = heatmap.shape[0], heatmap.shape[1]\n",
    "    ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
    "    br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
    "    if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
    "        return heatmap\n",
    "    size = 2 * tmp_size + 1\n",
    "    x = np.arange(0, size, 1, np.float32)\n",
    "    y = x[:, np.newaxis]\n",
    "    \n",
    "    x0 = y0 = size // 2\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
    "    g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
    "    img_x = max(0, ul[0]), min(br[0], h)\n",
    "    img_y = max(0, ul[1]), min(br[1], w)\n",
    "    \n",
    "    \n",
    "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
    "        heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
    "        g[g_y[0]:g_y[1], g_x[0]:g_x[1]])\n",
    "    return heatmap\n",
    "\n",
    "def gaussian_mask(mask):\n",
    "    xlist, ylist = np.where(mask == 1)\n",
    "    masklist = [(i,j) for i, j in zip(xlist, ylist)]\n",
    "    hm = np.zeros(mask.shape) \n",
    "\n",
    "    for (y,x) in masklist:\n",
    "        bbox = np.array([x-1, y-1, x+1, y+1])\n",
    "        h, w = bbox[3] - bbox[1], bbox[2] - bbox[0]\n",
    "        radius = gaussian_radius((h, w))    \n",
    "        ct = np.array([x,y], dtype=np.float32)\n",
    "        ct_int = ct.astype(np.int32)\n",
    "        #hm[int(bbox[1]): int(bbox[3]), int(bbox[0]): int(bbox[2])] = 0.9999    \n",
    "        hm = draw_msra_gaussian(hm, ct, 2) # np.exp((y-5)/200)\n",
    "    \n",
    "    return hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABxsAAAHeCAYAAABDvWVlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADt0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjByYzEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy/xvVyzAAAgAElEQVR4nOzdX4id95kf8OfRzBlJM5YqO3FdERsSWLMbX+SPK6e7bCnUbsqyLbYvlrBLKaYYfNOWlhbatHeFXmRvus1VwSTburDtJqRdFBazbbB3KYWSxpuk7a61NGlIkIMUq7GFRv/PzPx64ZPFTfS8mjyakY6szweC5pzved/3Ob/3nBMP33Pm5BgjAAAAAAAAAH5aB+70AAAAAAAAAMDdSdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAy+qtbJyZvxQRn42IlYj43BjjM1O3X8uD41Bs3MohAQAAAAAAgNvoalyK6+Na3ijLMUZrp5m5EhH/OyI+GRFvRMTXIuLXxhivV9sczQfGX8inWscDAAAAAAAAbr+vjlfiwnjrhmXjrfwZ1U9ExLfHGN8ZY1yPiN+OiGduYX8AAAAAAADAXeRWysYPRMTpd11+Y3EdAAAAAAAAcA+4pe9s3I3MfCEiXoiIOBTr+304AAAAAAAA4Da5lU82fj8iHnnX5YcX1/1/xhgvjjFOjDFOzOLgLRwOAAAAAAAAWCa3UjZ+LSIezcwPZeZaRPxqRHx5b8YCAAAAAAAAll37z6iOMbYy8+9ExH+KiJWI+M0xxh/v2WQAAAAAAADAUrul72wcY7wcES/v0SwAAAAAAADAXeRW/owqAAAAAAAAcA9TNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAlpuWjZn5m5n5Zmb+0buueyAzv5KZ31r8e//+jgkAAAAAAAAsm918svHfRMQv/dh1n46IV8YYj0bEK4vLAAAAAAAAwD3kpmXjGOO/RMRbP3b1MxHx0uLnlyLi2T2eCwAAAAAAAFhy3e9sfGiMcWbx89mIeGiP5gEAAAAAAADuEt2y8U+NMUZEjCrPzBcy87XMfG0e1271cAAAAAAAAMCS6JaNP8jM4xERi3/frG44xnhxjHFijHFiFgebhwMAAAAAAACWTbds/HJEPLf4+bmIOLk34wAAAAAAAAB3i5uWjZn57yPiv0XEz2bmG5n5fER8JiI+mZnfioi/srgMAAAAAAAA3ENWb3aDMcavFdFTezwLAAAAAAAAcBfp/hlVAAAAAAAA4B6nbAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC2rd3oAAAAAbkHmRLYP7y8dOxPZ2PvjAQAAsNR8shEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQsnqnBwAAgLte5kS2D+/vGzsT2dj743VYkxtrrkseqLfL1Ylf62azeruV+nhje2I95/N6u62tiX1u1/tcpnMEAADAT8UnGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtq3d6AAAA3iMyJ7J9eI/b2JnIxsQsvTnzQL1drk78Z/VsVm+3Uh9vbE/cv/m83m5rq852inWZWssJubJSZ3fLmmxv1/tsPo5u97rkkSNlNu47XGeziTnn9brkxSv1Pjc3y2zn0sR2W/X5mzwPAAAA3HE+2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoWb3TAwAAsGQy62hlpc5WJ/7Tcjab2Gf9/rexvVPvcz6vt9vaqo+3D3PmkSP1LPcdrrPZxHrOt+vs4pV6n5ubdVat59RaTpyDAxv1fbtb1mTn0sR2W/W65Gr9WLnd63L9fetldun4WpnN1+vn+uzyKLONM9fLbO30xLrEW2W2c7F+nE09n2+7idfHyH14L++YeA0c9TkCAAC4nXyyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCyeqcHAADgDsiso9VZmR3YOFxvd+RImY376u3GbKXe53y7zi5eqfe5uVlvtw9zXn/fepldOr5WZvP1+jzMLo8y2zhzvd7uh/eVWbWe3bWM9z9QRtceub/MbvearJ2eeEzHW2W2c3Gn3m7iuXC712W+UWcXPrxVZrNjV+t9nj9UZkdP1dmDUd+/g9fmZZZXr5XZ2K5fB2LUj4lJU6+BKxOvSasTv0LP6sdZrtTv8x3b9eMs5vWaja363O7LmgEAABR8shEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQsnqnBwAA4PbLlZUyO7BxuN7w/Q+U0bVH7i+zS8fXymy+nmU2uzzKbOPM9TJbOz0rs/2Yc75RZxc+vFVms2NX632eP1RmR0/V2ezSwTor1rO7ltcn1vLcR+oZb/eaPBj1nAevzcssr16rsyNHymzqMXa71+WZJ75eZk8efb3MXr3wWJmdjMfLbP1c/RxaOzvx2nK+fpzF9focxdius6yfl7laH2/qNXDqvI/76u3GrH7NzXl9H/LilXqfm5t1NvHYHVv142xsT6znqF+PAQCAe5tPNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABaVu/0AAAA7JPMOlqt/zMwjxwps2uP3F9m5z5yqMwufHirzGbHrpbZ/Hy9z6On6uzBWJ45n3ni62X25NHXy+zVC4+V2cl4vMw6c3bX8tLxtTKbWsvbvSbr5+o5184eLrM4PyujcV+93TKty9R2T29cLrOIeruXj9XHm69vlNmYrZRZruz9+2BzpT7egY2J8/7+B8po6jVw6rzP1+vX49nlUWYbZ66X2dRj98DFK2U2NjfLbOfSxHZb8zKLUd8HAADgvc8nGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtq3d6AAAA9klOvK9sNiujcd/hMrt0fK3MLnx4q8yeeeLrZfbk0dfL7NULj5XZyXi8zNbPLc+cU9s9vXG5zCLq7eKJOurM2V3L+XqW2ezY1TLbjzV5+Vh9DubrG2U2Zitlliv1c2hqu2Val6nHZne7+flDZTa7PMos59tlNrZ3ymxS1mudq/Wvu3nkSJlde+T+Mjv3kfq+T722TJ33qfU8eqrO1idejzfOXC+ztdP16/+BeKvMdi7W52hs1fcdAAB47/PJRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAEDL6s1ukJmPRMS/jYiHImJExItjjM9m5gMR8YWI+GBEfDciPjXGeHv/RgUAYK/kSv2eszFbKbP5epbZ7NjVMnvy6Otl9vTG5TKLqLd7+dhjZTZf3yiz2z3nqxfqObvb7fWc7bW8POrtzh8qs/1Yk6njTc2Z8+0yG9s7re2WaV1Ofu3xMps87xNzHj1V/xq5caZ+fuXFK2U25vMyi1Gfh8iJ98/OZvUu7ztcZpeOr5XZhQ9vldkzT3y9zKaes1Pnb+ocXZg8R3X2YNxfZgev1echr14rs7FdPx9i1M8HAADgvWE3n2zcioh/OMZ4LCJ+PiL+dmY+FhGfjohXxhiPRsQri8sAAAAAAADAPeKmZeMY48wY4+uLnzcj4lREfCAinomIlxY3eykint2vIQEAAAAAAIDlc9M/o/pumfnBiPh4RHw1Ih4aY5xZRGfjnT+zeqNtXoiIFyIiDsV6d04AAAAAAABgyezmz6hGRERm3hcR/yEi/v4Y48K7szHGiHe+z/EnjDFeHGOcGGOcmMXBWxoWAAAAAAAAWB67KhszcxbvFI2/Ncb4j4urf5CZxxf58Yh4c39GBAAAAAAAAJbRTcvGzMyI+HxEnBpj/It3RV+OiOcWPz8XESf3fjwAAAAAAABgWe3mOxt/MSL+ZkT8r8z85uK6fxoRn4mIL2bm8xHxvYj41P6MCADAXhvbO2WW8+0ym12+4V/Oj4iI+flDZfbqhccmpnm9td3U8ZZpzpNfe7zMXj7Wu3/xRB115uyu5caZ62V29FS9z5Ox92ty9FT9q83GmatllhevlNmYz1vb3S3rMru0UWeT571ez7XTb5fZ2Nyss62tMotRzxI5Ea3U760ds5Uym6/XO50dq+/7k0fr597TG5fLbOo5++Sfb77uTDyW1s+tldna2cNlFudndXa9fq7EqP8/BQAAeG+4adk4xvivUf8K99TejgMAAAAAAADcLXb1nY0AAAAAAAAAP07ZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWlbv9AAAAOyTsVNn83kZ5cUrZbZx5nqZHT11qMxOxuNl9vKxx8psfr7e59FT9X/Kbpy5OrHd8sw5u7RR73Mjy2yv5+yu5drpt8vswbi/zNbPrZXZfL1ek9nlUWbdOcfmZp1tbbW2Wzs9K7NlWpfZDy+XWc6362ziNWJqXXYuTWy3XR+va2zXr4FT929qPaee669eqJ97Ea9PZLWnN+pzNLXPydeBicfSmK2UWa54rzIAAHBjflsAAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtKze6QEAANgnY9TR1ladbW6W2drpWZk9GPeX2fq5tTKbr2+U2exyfR82zlwts7XTb5fZMs05++Hl+njvWy+zvZ6zu5bxf98qo4PX5vU+zx4uszFbKbOcb9fZxSv1Pice0zuXJrbbro83td2BuPvXZWzv1Nm8vg+Try0T6zn1ejVp1HPGxJxT67Jx5nqZHT11qMxOxuNl9vKxx8rslx99vcwi6uzVC/U+5+frOader6YeS1OPCQAA4N7mk40AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAltU7PQAAALff2N4us51LV8rsQLxVZgevzcts7ezhepbZSpnlvJ4zL9Zzjs3NMrtr5nz7SJnt9ZzdGaceK3n1WpnF+Vm93Ur9fsixvVNn8/q8jq2tiX3W5y7GmNhnfbydi/Wcd8267NT3PUZ9vKk12xeT52ji/k08rtdO1+fhwbi/zNbPrZXZ5QfvK7OT5x8vs5ePPVZm8/OHyuzoqfpX/Y0zV8ts8rVg4rE0+ZgAAADe83yyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCyeqcHAADgDhijjrbmZbZzcafM8uq1+njnZ/V2K/X738Z2fbwxr+ccW1v18cz5k9c3Zxzb2xPblVHE9fp4baM+B1OP9/7xpp5DvTV7T6zLEpla651LV8rsQLxVZgev1edo7ezhMtv4c0fKbP3cWpnN1zfKbHa5Pn8bZ66W2drpt8tsbG7W2cTj+r3+WAIAAKb5ZCMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgZfVODwAAwJIZo462tupse7ve5/X5rUxUHHBnIpu4D+a8wcF6M/aPN3Hf3uum1vNeXpf9MPlaVj+Hdi7Wz4e8eq3ONg+W2cGLV8ps7ezhMhuzlfp48/rxkhPHG5ubZbZzaWK7qdckAADgnuaTjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAICW1Ts9AAAA7xFjTGTbt2+OmzEnMPH8GltbdbZdP/dyYru8eq2e5fys3m6lfn/w2N6ps/m8zpr3b/I1CQAAuKf5ZCMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgZfVODwAAAAB3hTHqaGurzra3631en9/KRMUBdyay+j4AAAB0+GQjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoGX1Tg8AAAAA72ljTGTbt28OAACAfeCTjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALTctGzMzEOZ+d8z839k5h9n5j9bXP+hzPxqZn47M7+QmWv7Py4AAAAAAACwLHbzycZrEfHkGOOjEfGxiPilzPz5iPj1iPiNMcbPRMTbEfH8/o0JAAAAAAAALJublo3jHRcXF2eL/42IeDIivrS4/qWIeHZfJgQAAAAAAACW0q6+szEzVzLzmxHxZkR8JSL+T0ScH2NsLW7yRkR8YH9GBAAAAAAAAJbRrsrGMcb2GONjEfFwRHwiIn5utwfIzBcy87XMfG0e15pjAgAAAAAAAMtmV2Xjj4wxzkfE70fEL0TEscxcXUQPR8T3i21eHGOcGGOcmMXBWxoWAAAAAAAAWB43LRsz88HMPLb4+XBEfDIiTsU7peOvLG72XESc3K8hAQAAAAAAgOWzevObxPGIeCkzV+KdcvKLY4zfzczXI+K3M/OfR8Q3IuLz+zgnAAAAAAAAsGRuWjaOMf5nRHz8Btd/J975/kYAAAAAAADgHvRTfWcjAAAAAAAAwI8oGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAy67LxsxcycxvZObvLi5/KDO/mpnfzswvZOba/o0JAAAAAAAALJuf5pONfy8iTr3r8q9HxG+MMX4mIt6OiOf3cjAAAAAAAABgue2qbMzMhyPir0XE5xaXMyKejIgvLW7yUkQ8ux8DAgAAAAAAAMtpt59s/JcR8Y8iYmdx+X0RcX6MsbW4/EZEfGCPZwMAAAAAAACW2E3Lxsz86xHx5hjjDzsHyMwXMvO1zHxtHtc6uwAAAAAAAACW0OoubvOLEfF0Zv5yRByKiKMR8dmIOJaZq4tPNz4cEd+/0cZjjBcj4sWIiKP5wNiTqQEAAAAAAIA77qafbBxj/JMxxsNjjA9GxK9GxKtjjL8REb8fEb+yuNlzEXFy36YEAAAAAAAAls5uv7PxRv5xRPyDzPx2vPMdjp/fm5EAAAAAAACAu8Fu/ozqnxpj/EFE/MHi5+9ExCf2fiQAAAAAAADgbnArn2wEAAAAAAAA7mHKRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQsrqbG2XmdyNiMyK2I2JrjHEiMx+IiC9ExAcj4rsR8akxxtv7MyYAAAAAAACwbH6aTzb+5THGx8YYJxaXPx0Rr4wxHo2IVxaXAQAAAAAAgHvErfwZ1Wci4qXFzy9FxLO3Pg4AAAAAAABwt9ht2Tgi4j9n5h9m5guL6x4aY5xZ/Hw2Ih7a8+kAAAAAAACApbWr72yMiL84xvh+Zv7ZiPhKZv7Ju8MxxsjMcaMNF+XkCxERh2L9loYFAAAAAAAAlseuPtk4xvj+4t83I+J3IuITEfGDzDweEbH4981i2xfHGCfGGCdmcXBvpgYAAAAAAADuuJuWjZm5kZlHfvRzRPzViPijiPhyRDy3uNlzEXFyv4YEAAAAAAAAls9u/ozqQxHxO5n5o9v/uzHG72Xm1yLii5n5fER8LyI+tX9jAgAAAAAAAMvmpmXjGOM7EfHRG1z/w4h4aj+GAgAAAAAAAJbfrr6zEQAAAAAAAODHKRsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQIuyEQAAAAAAAGhRNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAAAA0KJsBAAAAAAAAFqUjQAAAAAAAECLshEAAAAAAABoUTYCAAAAAAAALcpGAAAAAAAAoEXZCAAAAAAAALQoGwEAAAAAAIAWZSMAAAAAAADQomwEAAAAAAAAWpSNAAAAAAAAQMuuysbMPJaZX8rMP8nMU5n5C5n5QGZ+JTO/tfj3/v0eFgAAAAAAAFgeu/1k42cj4vfGGD8XER+NiFMR8emIeGWM8WhEvLK4DAAAAAAAANwjblo2ZuafiYi/FBGfj4gYY1wfY5yPiGci4qXFzV6KiGf3a0gAAAAAAABg+ezmk40fiohzEfGvM/Mbmfm5zNyIiIfGGGcWtzkbEQ/daOPMfCEzX8vM1+ZxbW+mBgAAAIJX9nYAAAZRSURBVAAAAO643ZSNqxHxeET8qzHGxyPiUvzYn0wdY4yIGDfaeIzx4hjjxBjjxCwO3uq8AAAAAAAAwJLYTdn4RkS8Mcb46uLyl+Kd8vEHmXk8ImLx75v7MyIAAAAAAACwjG5aNo4xzkbE6cz82cVVT0XE6xHx5Yh4bnHdcxFxcl8mBAAAAAAAAJbS6i5v93cj4rcycy0ivhMRfyveKSq/mJnPR8T3IuJT+zMiAAAAAAAAsIx2VTaOMb4ZESduED21t+MAAAAAAAAAd4vdfGcjAAAAAAAAwE9QNgIAAAAAAAAtykYAAAAAAACgRdkIAAAAAAAAtCgbAQAAAAAAgBZlIwAAAAAAANCibAQAAAAAAABalI0AAAAAAABAi7IRAAAAAAAAaFE2AgAAAAAAAC3KRgAAAAAAAKBF2QgAAAAAAAC0KBsBAAAAAACAFmUjAAAAAPD/2rufUM3qMg7g3wetFhloGEOopMRsps0oIoIRtjF1M7URXZSIYIsRCtqYG1u6USEooWjQoBKhJBeihgStKv8wqKNIQyk6TE4RVBAYY0+L90hv030H5+2dczzv/Xzg8p7zO/dyHu7iex/Ow/0dAIC1GDYCAAAAAAAAazFsBAAAAAAAANZi2AgAAAAAAACsxbARAAAAAAAAWIthIwAAAAAAALCW6u7xblb1pyRvDKcXJvnzaDcH2N1kLsB4ZC7AeGQuwDjkLcB4PqiZ+6nu/sROF0YdNv7Xjaue6+4rJ7k5wC4jcwHGI3MBxiNzAcYhbwHGM8fMtY0qAAAAAAAAsBbDRgAAAAAAAGAtUw4bvzfhvQF2G5kLMB6ZCzAemQswDnkLMJ7ZZe5k72wEAAAAAAAA5s02qgAAAAAAAMBaJhk2VtX1VfVaVR2tqrumqAFgm1XV61X1UlUdrqrnhrWPV9Uvqup3w+cFU9cJMEdVdaiqTlTVy0trO2ZsLXx76HtfrKorpqscYF5W5O23qurY0Ocerqobl659c8jb16rqC9NUDTBPVXVJVf2yql6pqiNV9bVhXZ8LsEGnydtZ97mjDxur6pwk30lyQ5J9SW6pqn1j1wGwC3y+u/d395XD+V1JnunuvUmeGc4BOHMPJbn+lLVVGXtDkr3D1x1JHhypRoBt8FD+N2+T5IGhz93f3U8kyfBc4eYknxl+5rvD8wcA3p+TSb7R3fuSXJ3k4JCt+lyAzVqVt8mM+9wp/rPxqiRHu/v33f3PJI8kOTBBHQC7zYEkDw/HDyf54oS1AMxWd/8qyV9OWV6VsQeS/LAXfp3k/Kr65DiVAszbirxd5UCSR7r7ne7+Q5KjWTx/AOB96O7j3f3CcPz3JK8muSj6XICNOk3erjKLPneKYeNFSd5cOn8rp/9FAnDmOsnTVfV8Vd0xrO3p7uPD8R+T7JmmNICttCpj9b4Am3fnsGXfoaVXA8hbgA2pqkuTXJ7kN9HnApw1p+RtMuM+d5J3NgJw1n22u6/IYluTg1X1ueWL3d1ZDCQB2DAZC3BWPZjk00n2Jzme5L5pywHYLlV1XpKfJvl6d/9t+Zo+F2BzdsjbWfe5UwwbjyW5ZOn84mENgA3p7mPD54kkj2Xxr/Vvv7elyfB5YroKAbbOqozV+wJsUHe/3d3vdve/knw//9lCSt4C/J+q6kNZPPj+UXf/bFjW5wJs2E55O/c+d4ph47NJ9lbVZVX14SxebPn4BHUAbKWq+mhVfey94yTXJXk5i6y9dfi2W5P8fJoKAbbSqox9PMlXauHqJH9d2oYKgDN0yvvAvpRFn5ss8vbmqvpIVV2WZG+S345dH8BcVVUl+UGSV7v7/qVL+lyADVqVt3Pvc88d+4bdfbKq7kzyVJJzkhzq7iNj1wGwxfYkeWzxdyvnJvlxdz9ZVc8mebSqbk/yRpKbJqwRYLaq6idJrk1yYVW9leSeJPdm54x9IsmNWbzA/R9Jbhu9YICZWpG311bV/iy28Xs9yVeTpLuPVNWjSV5JcjLJwe5+d4q6AWbqmiRfTvJSVR0e1u6OPhdg01bl7S1z7nNrsdU2AAAAAAAAwJmZYhtVAAAAAAAAYAsYNgIAAAAAAABrMWwEAAAAAAAA1mLYCAAAAAAAAKzFsBEAAAAAAABYi2EjAAAAAAAAsBbDRgAAAAAAAGAtho0AAAAAAADAWv4NjVRaH2jERSUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2304x2304 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(32,32))\n",
    "plt.imshow(gaussian_mask(train_dataset[2][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def _neg_loss(pred, gt):\n",
    "    ''' Modified focal loss. Exactly the same as CornerNet.\n",
    "      Runs faster and costs a little bit more memory\n",
    "    Arguments:\n",
    "      pred (batch x c x h x w)\n",
    "      gt_regr (batch x c x h x w)\n",
    "    '''\n",
    "    \n",
    "    for i in range(gt.shape[0]):\n",
    "        gt[i] = torch.from_numpy(gaussian_mask(gt[i].cpu()))\n",
    "    \n",
    "    pos_inds = gt.eq(1).float()\n",
    "    neg_inds = gt.lt(1).float()\n",
    "\n",
    "    neg_weights = torch.pow(1 - gt, 4)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    pos_loss = torch.log(pred) * torch.pow(1 - pred, 2) * pos_inds\n",
    "    neg_loss = torch.log(1 - pred) * torch.pow(pred, 2) * neg_weights * neg_inds\n",
    "\n",
    "    num_pos  = pos_inds.float().sum()\n",
    "    pos_loss = pos_loss.sum()\n",
    "    neg_loss = neg_loss.sum()\n",
    "\n",
    "    if num_pos == 0:\n",
    "        loss = loss - neg_loss\n",
    "    else:\n",
    "        loss = loss - (pos_loss + neg_loss) / num_pos\n",
    "    return loss\n",
    "\n",
    "def criterion(prediction, mask, regr, weight=0.8, size_average=True):\n",
    "\n",
    "    # Binary mask loss\n",
    "    pred_mask = prediction[0]['hm']\n",
    "    pred_mask = torch.sigmoid(pred_mask[:, 0])\n",
    "#     mask_loss = mask * (1 - pred_mask)**2 * torch.log(pred_mask + 1e-12) + (1 - mask) * pred_mask**2 * torch.log(1 - pred_mask + 1e-12)\n",
    "\n",
    "    #mask_loss = mask * torch.log(pred_mask + 1e-12) + (1 - mask) * torch.log(1 - pred_mask + 1e-12)\n",
    "    #mask_loss = -mask_loss.mean(0).sum()\n",
    "    \n",
    "    mask_loss = _neg_loss(pred_mask,mask)\n",
    "    \n",
    "    # Regression L1 loss\n",
    "    #pred_regr = prediction[:, 1:]\n",
    "    pred_regr = prediction[0]['reg']\n",
    "    #regr_loss = (torch.abs(pred_regr - regr).sum(1) * mask).sum(1).sum(1) / mask.sum(1).sum(1\n",
    "    \n",
    "    #for i in range(regr.shape[0]):\n",
    "    #    for j in range(regr.shape[1]):\n",
    "    #        regr[i][j] = torch.from_numpy(gaussian_mask_reg(regr[i][j].cpu()))\n",
    "\n",
    "    regr_loss = (torch.min(torch.abs(pred_regr - regr), torch.abs((pred_regr - regr)**2)).sum(1) * mask).sum(1).sum(1) / mask.sum(1).sum(1)\n",
    "    # smooth l1 - torch.min(torch.abs(pred_regr - regr), torch.abs((pred_regr - regr)**2))\n",
    "    regr_loss = regr_loss.mean(0)\n",
    "\n",
    "    # Sum\n",
    "    loss = weight*mask_loss +(1-weight)* regr_loss\n",
    "    #if not size_average:\n",
    "    #    loss *= prediction.shape[0]\n",
    "    return loss ,mask_loss , regr_loss\n",
    "\n",
    "def train(epoch, history=None):\n",
    "    model.train()\n",
    "    t = tqdm(train_loader)\n",
    "    for batch_idx, (img_batch, mask_batch, regr_batch) in enumerate(t):\n",
    "        img_batch = img_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "        regr_batch = regr_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(img_batch)\n",
    "        \n",
    "        if epoch < SWITCH_LOSS_EPOCH :\n",
    "            loss, mask_loss, regr_loss = criterion(output, mask_batch, regr_batch,1)\n",
    "        else:\n",
    "            loss,mask_loss, regr_loss = criterion(output, mask_batch, regr_batch,0.5)  \n",
    "        \n",
    "        t.set_description(f'train_loss (l={loss:.3f})(m={mask_loss:.2f}) (r={regr_loss:.4f}')\n",
    "        \n",
    "        if history is not None:\n",
    "            history.loc[epoch + batch_idx / len(train_loader), 'train_loss'] = loss.data.cpu().numpy()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        exp_lr_scheduler.step()\n",
    "\n",
    "    \n",
    "    print('Train Epoch: {} \\tLR: {:.6f}\\tLoss: {:.6f}\\tMaskLoss: {:.6f}\\tRegLoss: {:.6f}'.format(\n",
    "        epoch,\n",
    "        optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "        loss.data,\n",
    "        mask_loss.data,\n",
    "        regr_loss.data))\n",
    "\n",
    "def evaluate(epoch, history=None):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    valid_loss = 0\n",
    "    valid_mask_loss = 0\n",
    "    valid_regr_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for img_batch, mask_batch, regr_batch in dev_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            mask_batch = mask_batch.to(device)\n",
    "            regr_batch = regr_batch.to(device)\n",
    "\n",
    "            output = model(img_batch)\n",
    "\n",
    "            if epoch < SWITCH_LOSS_EPOCH :\n",
    "                loss,mask_loss, regr_loss= criterion(output, mask_batch, regr_batch,1, size_average=False)\n",
    "                valid_loss += loss.data\n",
    "                valid_mask_loss += mask_loss.data\n",
    "                valid_regr_loss += regr_loss.data\n",
    "            else :\n",
    "                loss,mask_loss, regr_loss = criterion(output, mask_batch, regr_batch,0.5, size_average=False)\n",
    "                valid_loss += loss.data\n",
    "                valid_mask_loss += mask_loss.data\n",
    "                valid_regr_loss += regr_loss.data \n",
    "\n",
    "    \n",
    "    valid_loss /= len(dev_loader.dataset)\n",
    "    valid_mask_loss /= len(dev_loader.dataset)\n",
    "    valid_regr_loss /= len(dev_loader.dataset)\n",
    "    \n",
    "    if history is not None:\n",
    "        history.loc[epoch, 'dev_loss'] = valid_loss.cpu().numpy()\n",
    "        history.loc[epoch, 'mask_loss'] = valid_mask_loss.cpu().numpy()\n",
    "        history.loc[epoch, 'regr_loss'] = valid_regr_loss.cpu().numpy()\n",
    "\n",
    "    \n",
    "    print('Dev loss: {:.4f}'.format(valid_loss))\n",
    "    return valid_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dohee/anaconda3/envs/CenterNet/lib/python3.6/site-packages/ipykernel_launcher.py:67: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07290b7a3f4437ab099e1c9b23da339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1055.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 0 \tLR: 0.001000\tLoss: 0.523993\tMaskLoss: 0.523993\tRegLoss: 0.065512\n",
      "Dev loss: 0.2222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc16384e79c4cfb84f166a6ac7b5b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1055.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 1 \tLR: 0.001000\tLoss: 0.535228\tMaskLoss: 0.535228\tRegLoss: 0.059469\n",
      "Dev loss: 0.1787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221c93d184244e59b22312138affe0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1055.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 2 \tLR: 0.001000\tLoss: 0.713570\tMaskLoss: 0.713570\tRegLoss: 0.066142\n",
      "Dev loss: 0.1520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fb827bd1ac414bbf9b2c086032110c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1055.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "history = pd.DataFrame()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    train(epoch, history)\n",
    "    valid_loss = evaluate(epoch, history)\n",
    "    \n",
    "    model_name = 'dla34'\n",
    "    torch.save(model.state_dict(), './model-'+'_'+model_name+'_' +str(epoch)+'_'+str(valid_loss)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dla34'\n",
    "torch.save(model.state_dict(), './model-'+'_'+model_name+'_'+str(valid_loss)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['train_loss'].iloc[100:].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = history.dropna()['mask_loss']\n",
    "plt.plot(series1.index, series1 ,label = 'mask loss');\n",
    "series2 = history.dropna()['regr_loss']\n",
    "plt.plot(series2.index, 30*series2,label = 'regr loss');\n",
    "series3 = history.dropna()['dev_loss']\n",
    "plt.plot(series3.index, series3,label = 'dev loss', color = 'red');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = history.dropna()['dev_loss']\n",
    "plt.scatter(series.index, series);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load( './model-dla34'+'_'+'w08'+'.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10,20):\n",
    "    img, mask, regr = dev_dataset[i]\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Input image')\n",
    "    plt.imshow(np.rollaxis(img, 0, 3))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Ground truth mask')\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "\n",
    "    output = model(torch.tensor(img[None]).to(device))\n",
    "    logits = output[0]['hm'].data.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Model predictions')\n",
    "    plt.imshow(logits[0,0])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Model predictions thresholded')\n",
    "    plt.imshow(logits[0,0] > -1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_THRESH_CLEAR = 2\n",
    "\n",
    "def convert_3d_to_2d(x, y, z, fx = 2304.5479, fy = 2305.8757, cx = 1686.2379, cy = 1354.9849):\n",
    "    # stolen from https://www.kaggle.com/theshockwaverider/eda-visualization-baseline\n",
    "    return x * fx / z + cx, y * fy / z + cy\n",
    "\n",
    "def optimize_xy(r, c, x0, y0, z0):\n",
    "    def distance_fn(xyz):\n",
    "        x, y, z = xyz\n",
    "        x, y = convert_3d_to_2d(x, y, z0)\n",
    "        y, x = x, y\n",
    "        x = (x - IMG_SHAPE[0] // 2) * IMG_HEIGHT / (IMG_SHAPE[0] // 2) / MODEL_SCALE\n",
    "        x = np.round(x).astype('int')\n",
    "        y = (y + IMG_SHAPE[1] // 4) * IMG_WIDTH / (IMG_SHAPE[1] * 1.5) / MODEL_SCALE\n",
    "        y = np.round(y).astype('int')\n",
    "        return (x-r)**2 + (y-c)**2\n",
    "    \n",
    "    res = minimize(distance_fn, [x0, y0, z0], method='Powell')\n",
    "    x_new, y_new, z_new = res.x\n",
    "    return x_new, y_new, z0\n",
    "\n",
    "def clear_duplicates(coords):\n",
    "    for c1 in coords:\n",
    "        xyz1 = np.array([c1['x'], c1['y'], c1['z']])\n",
    "        for c2 in coords:\n",
    "            xyz2 = np.array([c2['x'], c2['y'], c2['z']])\n",
    "            distance = np.sqrt(((xyz1 - xyz2)**2).sum())\n",
    "            if distance < DISTANCE_THRESH_CLEAR:\n",
    "                if c1['confidence'] < c2['confidence']:\n",
    "                    c1['confidence'] = -1\n",
    "    return [c for c in coords if c['confidence'] > 0]\n",
    "\n",
    "def coords2str(coords, names=['yaw', 'pitch', 'roll', 'x', 'y', 'z', 'confidence']):\n",
    "    s = []\n",
    "    for c in coords:\n",
    "        for n in names:\n",
    "            s.append(str(c.get(n, 0)))\n",
    "    return ' '.join(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from math import sqrt, acos, pi, sin, cos\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from inspect import signature\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def expand_df(df, PredictionStringCols):\n",
    "    df = df.dropna().copy()\n",
    "    df['NumCars'] = [int((x.count(' ')+1)/7) for x in df['PredictionString']]\n",
    "\n",
    "    image_id_expanded = [item for item, count in zip(df['ImageId'], df['NumCars']) for i in range(count)]\n",
    "    prediction_strings_expanded = df['PredictionString'].str.split(' ',expand = True).values.reshape(-1,7).astype(float)\n",
    "    prediction_strings_expanded = prediction_strings_expanded[~np.isnan(prediction_strings_expanded).all(axis=1)]\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'ImageId': image_id_expanded,\n",
    "            PredictionStringCols[0]:prediction_strings_expanded[:,0],\n",
    "            PredictionStringCols[1]:prediction_strings_expanded[:,1],\n",
    "            PredictionStringCols[2]:prediction_strings_expanded[:,2],\n",
    "            PredictionStringCols[3]:prediction_strings_expanded[:,3],\n",
    "            PredictionStringCols[4]:prediction_strings_expanded[:,4],\n",
    "            PredictionStringCols[5]:prediction_strings_expanded[:,5],\n",
    "            PredictionStringCols[6]:prediction_strings_expanded[:,6]\n",
    "        })\n",
    "    return df\n",
    "\n",
    "def TranslationDistance(p,g, abs_dist = False):\n",
    "    dx = p['x'] - g['x']\n",
    "    dy = p['y'] - g['y']\n",
    "    dz = p['z'] - g['z']\n",
    "    diff0 = (g['x']**2 + g['y']**2 + g['z']**2)**0.5\n",
    "    diff1 = (dx**2 + dy**2 + dz**2)**0.5\n",
    "    if abs_dist:\n",
    "        diff = diff1\n",
    "    else:\n",
    "        diff = diff1/diff0\n",
    "    return diff\n",
    "\n",
    "def RotationDistance(p, g):\n",
    "    true=[ g['pitch'] ,g['yaw'] ,g['roll'] ]\n",
    "    pred=[ p['pitch'] ,p['yaw'] ,p['roll'] ]\n",
    "    q1 = R.from_euler('xyz', true)\n",
    "    q2 = R.from_euler('xyz', pred)\n",
    "    diff = R.inv(q2) * q1\n",
    "    W = np.clip(diff.as_quat()[-1], -1., 1.)\n",
    "    \n",
    "    # in the official metrics code:\n",
    "    # https://www.kaggle.com/c/pku-autonomous-driving/overview/evaluation\n",
    "    #   return Object3D.RadianToDegree( Math.Acos(diff.W) )\n",
    "    # this code treat θ and θ+2π differntly.\n",
    "    # So this should be fixed as follows.\n",
    "    W = (acos(W)*360)/pi\n",
    "    if W > 180:\n",
    "        W = 360 - W\n",
    "    return W\n",
    "\n",
    "def print_pr_curve(result_flg, scores, recall_total=1):\n",
    "    average_precision = average_precision_score(result_flg, scores)\n",
    "    precision, recall, _ = precision_recall_curve(result_flg, scores)\n",
    "    recall *= recall_total\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_tr_list = [0.1, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01]\n",
    "thres_ro_list = [50, 45, 40, 35, 30, 25, 20, 15, 10, 5]\n",
    "\n",
    "def check_match(idx):\n",
    "    keep_gt=False\n",
    "    thre_tr_dist = thres_tr_list[idx]\n",
    "    thre_ro_dist = thres_ro_list[idx]\n",
    "    train_dict = {imgID:str2coords(s, names=['carid_or_score', 'pitch', 'yaw', 'roll', 'x', 'y', 'z']) for imgID,s in zip(train_df['ImageId'],train_df['PredictionString'])}\n",
    "    valid_dict = {imgID:str2coords(s, names=['pitch', 'yaw', 'roll', 'x', 'y', 'z', 'carid_or_score']) for imgID,s in zip(valid_df['ImageId'],valid_df['PredictionString'])}\n",
    "    result_flg = [] # 1 for TP, 0 for FP\n",
    "    scores = []\n",
    "    MAX_VAL = 10**10\n",
    "    for img_id in valid_dict:\n",
    "        for pcar in sorted(valid_dict[img_id], key=lambda x: -x['carid_or_score']):\n",
    "            # find nearest GT\n",
    "            min_tr_dist = MAX_VAL\n",
    "            min_idx = -1\n",
    "            for idx, gcar in enumerate(train_dict[img_id]):\n",
    "                tr_dist = TranslationDistance(pcar,gcar)\n",
    "                if tr_dist < min_tr_dist:\n",
    "                    min_tr_dist = tr_dist\n",
    "                    min_ro_dist = RotationDistance(pcar,gcar)\n",
    "                    min_idx = idx\n",
    "                    \n",
    "            # set the result\n",
    "            if min_tr_dist < thre_tr_dist and min_ro_dist < thre_ro_dist:\n",
    "                if not keep_gt:\n",
    "                    train_dict[img_id].pop(min_idx)\n",
    "                result_flg.append(1)\n",
    "            else:\n",
    "                result_flg.append(0)\n",
    "            scores.append(pcar['carid_or_score'])\n",
    "    \n",
    "    return result_flg, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = -1\n",
    "threshold2 = 1\n",
    "threshold3 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coords(prediction, threshold1):\n",
    "    \n",
    "    img = prediction[0][0].cpu().numpy()\n",
    "    #logits = prediction[0][0].cpu().numpy()\n",
    "    logits = peak_tmp(prediction[0].cpu().numpy(), threshold1, threshold2, threshold3)\n",
    "    \n",
    "    regr_output = prediction[1].cpu().numpy()\n",
    "    points = np.argwhere(logits > threshold1)\n",
    "\n",
    "    # top 100 points\n",
    "    (xlist, ylist) =  np.where(img>np.sort(img.reshape((1,-1)))[0][-100])\n",
    "    top_list = [pair for pair in zip(list(xlist), list(ylist))]\n",
    "    \n",
    "    col_names = sorted(['x', 'y', 'z', 'yaw', 'pitch_sin', 'pitch_cos', 'roll'])\n",
    "    coords = []\n",
    "    \n",
    "    for r, c in points:\n",
    "        if (r,c) not in top_list:\n",
    "            continue\n",
    "            \n",
    "        regr_dict = dict(zip(col_names, regr_output[:, r, c]))\n",
    "        coords.append(_regr_back(regr_dict))\n",
    "        coords[-1]['confidence'] = 1 / (1 + np.exp(-logits[r, c]))\n",
    "        coords[-1]['x'], coords[-1]['y'], coords[-1]['z'] = optimize_xy(r, c, coords[-1]['x'], coords[-1]['y'], coords[-1]['z'])\n",
    "    coords = clear_duplicates(coords)\n",
    "    return coords\n",
    "\n",
    "def extract_coords_tmp(prediction, threshold1, threshold2, threshold3):\n",
    "    \n",
    "    img = prediction[0][0].cpu().numpy()\n",
    "    logits = peak_tmp(prediction[0].cpu().numpy(), threshold1, threshold2, threshold3)\n",
    "    #logits = prediction[0][0].cpu().numpy()\n",
    "    \n",
    "    regr_output = prediction[1].cpu().numpy()\n",
    "    points = np.argwhere(logits > threshold1)\n",
    "\n",
    "    # top 100 points\n",
    "    (xlist, ylist) =  np.where(img>np.sort(img.reshape((1,-1)))[0][-100])\n",
    "    top_list = [pair for pair in zip(list(xlist), list(ylist))]\n",
    "    \n",
    "    col_names = sorted(['x', 'y', 'z', 'yaw', 'pitch_sin', 'pitch_cos', 'roll'])\n",
    "    coords = []\n",
    "    \n",
    "    for r, c in points:\n",
    "        if (r,c) not in top_list:\n",
    "            continue\n",
    "            \n",
    "        regr_dict = dict(zip(col_names, regr_output[:, r, c]))\n",
    "        coords.append(_regr_back(regr_dict))\n",
    "        coords[-1]['confidence'] = 1 / (1 + np.exp(-logits[r, c]))\n",
    "        coords[-1]['x'], coords[-1]['y'], coords[-1]['z'] = optimize_xy(r, c, coords[-1]['x'], coords[-1]['y'], coords[-1]['z'])\n",
    "    coords = clear_duplicates(coords)\n",
    "    return coords\n",
    "\n",
    "def peak_tmp(array, threshold1, threshold2, threshold3):\n",
    "    (xlist, ylist) = np.where(array[0]>np.sort(array[0].reshape((1,-1)))[0][-100])\n",
    "    \n",
    "    peak_array = array[0]\n",
    "    maximum = array.max()\n",
    "    threshold_iter = 0\n",
    "    \n",
    "    while np.sum(peak_array>threshold1)<5 and threshold_iter<8:\n",
    "        threshold_iter+=1\n",
    "        peak_array += 0.5\n",
    "        print(\"brighter:\", np.sum(peak_array>threshold1))\n",
    "    \n",
    "    advantage = np.zeros(array[0].shape)\n",
    "    penalty = np.zeros(array[0].shape)\n",
    "    \n",
    "    for k in range(len(xlist)):\n",
    "        i = xlist[k]\n",
    "        j = ylist[k]\n",
    "        ct1 = 0 # 주변의 점들이 top 100 안에 있는가\n",
    "        ct2 = 0 # 주변의 점들의 값이 더 작은가 \n",
    "        \n",
    "        if 0<i<array.shape[1]-1 and 0<j<array.shape[2]-1:    \n",
    "            surroundings = [(i-1,j+1),(i-1,j),(i-1,j+1),(i,j-1),(i,j+1),(i+1,j+1),(i+1,j),(i+1,j+1)]\n",
    "            for xy in surroundings:\n",
    "                if (xy[0], xy[1]) in list(zip(xlist, ylist)):                    \n",
    "                    ct1 += 1\n",
    "                if peak_array[i,j] > peak_array[xy[0], xy[1]]:\n",
    "                    ct2 += 1\n",
    "            if ct1 > 6 and ct2 > 7:\n",
    "                advantage[i,j] += min((maximum - peak_array[i,j])*(1/2),2)\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(1,array.shape[1]-1):\n",
    "        for j in range(1,array.shape[2]-1):    \n",
    "            ct_sur = 0\n",
    "            ct_vert = 0\n",
    "            ct_hori = 0\n",
    "            surroundings = [(i,j),(i,j+1),(i+1,j),(i+1,j+1)]\n",
    "            horizontal = [(i,j-1),(i,j),(i,j+1)]\n",
    "            vertical = [(i-1,j),(i,j),(i+1,j)] \n",
    "            \n",
    "            for xy in surroundings:\n",
    "                if array[0][xy[0],xy[1]]>threshold1:\n",
    "                    ct_sur += 1\n",
    "                    \n",
    "            for xy in vertical:\n",
    "                if array[0][xy[0],xy[1]]>threshold1:\n",
    "                    ct_vert += 1\n",
    "\n",
    "            for xy in vertical:\n",
    "                if array[0][xy[0],xy[1]]>threshold1:\n",
    "                    ct_hori += 1\n",
    "\n",
    "            if ct_sur > 2:\n",
    "                idx_small = np.array([array[0][i,j],array[0][i,j+1],array[0][i+1,j],array[0][i+1,j+1]]).argsort()[:2]\n",
    "                idx_list = [[i,j],[i,j+1],[i+1,j],[i+1,j+1]]\n",
    "                for i in idx_small:\n",
    "                    penalty[idx_list[i][0], idx_list[i][1]] -= 1\n",
    "\n",
    "            if ct_vert == 3:\n",
    "                idx_small = np.array([array[0][i-1,j],array[0][i,j],array[0][i+1,j]]).argsort()[:2]\n",
    "                idx_list = [[i-1,j],[i,j],[i+1,j]]\n",
    "                for i in idx_small:\n",
    "                    penalty[idx_list[i][0], idx_list[i][1]] -= 1\n",
    "\n",
    "            if ct_hori == 3:\n",
    "                idx_small = np.array([array[0][i-1,j],array[0][i,j],array[0][i+1,j]]).argsort()[:1]\n",
    "                idx_list = [[i,j-1],[i,j],[i,j+1]]\n",
    "                for i in idx_small:\n",
    "                    penalty[idx_list[i][0], idx_list[i][1]] -= 1\n",
    "\n",
    "    #print(\"advantage:\", np.sum(advantage)*threshold2)\n",
    "    #print(\"penalty:\", np.sum(penalty)*threshold3)\n",
    "    \n",
    "    \n",
    "    peak_array = peak_array = peak_array + advantage*threshold2 + penalty*threshold3\n",
    "    \n",
    "    return peak_array #, advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "predictions = []\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "model.eval()\n",
    "for img, _, _ in tqdm(dev_loader):\n",
    "    with torch.no_grad():\n",
    "        output = model(img.to(device))\n",
    "    \n",
    "    for i in range(output[0]['hm'].shape[0]):\n",
    "        #coords = extract_coords((output[0]['hm'][i], output[0]['reg'][i]),-1.5)\n",
    "        coords = extract_coords_tmp((output[0]['hm'][i], output[0]['reg'][i]), threshold1,threshold2,threshold3 )\n",
    "        s = coords2str(coords)\n",
    "        predictions.append(s)\n",
    "        \n",
    "df_dev['PredictionString'] = copy.copy(predictions)\n",
    "\n",
    "valid_df = df_dev\n",
    "expanded_valid_df = expand_df(valid_df, ['pitch','yaw','roll','x','y','z','Score'])\n",
    "valid_df = valid_df.fillna('')\n",
    "\n",
    "train_df = pd.read_csv('../input/pku-autonomous-driving/train.csv')\n",
    "train_df = train_df[train_df.ImageId.isin(valid_df.ImageId.unique())]\n",
    "# data description page says, The pose information is formatted as\n",
    "# model type, yaw, pitch, roll, x, y, z\n",
    "# but it doesn't, and it should be\n",
    "# model type, pitch, yaw, roll, x, y, z\n",
    "expanded_train_df = expand_df(train_df, ['model_type','pitch','yaw','roll','x','y','z'])\n",
    "\n",
    "max_workers = 10\n",
    "n_gt = len(expanded_train_df)\n",
    "ap_list = []\n",
    "p = Pool(processes=max_workers)\n",
    "for result_flg, scores in p.imap(check_match, range(10)):\n",
    "    if np.sum(result_flg) > 0:\n",
    "        n_tp = np.sum(result_flg)\n",
    "        recall = n_tp/n_gt\n",
    "        ap = average_precision_score(result_flg, scores)*recall\n",
    "        print_pr_curve(result_flg, scores, recall)\n",
    "    else:\n",
    "        ap = 0\n",
    "    ap_list.append(ap)\n",
    "map = np.mean(ap_list)\n",
    "print('map:', map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = -1\n",
    "threshold2 = 1\n",
    "threshold3 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(40,50):\n",
    "    img, mask, regr = train_dataset[i]\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Input image')\n",
    "    plt.imshow(np.rollaxis(img, 0, 3))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Ground truth mask')\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "    \n",
    "    output = model(torch.tensor(img[None]).to(device))\n",
    "    output = output[0]['hm']\n",
    "    logits = output[0,0].data.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Model predictions')\n",
    "    plt.imshow(logits)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Model predictions thresholded')\n",
    "    plt.imshow(logits>-1)\n",
    "    plt.show()\n",
    "    \n",
    "    img = peak_tmp(output[0].detach().cpu().numpy(),threshold1,threshold2,threshold3)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('peak')\n",
    "    plt.imshow(img>threshold1)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_coords(prediction, threshold1, threshold2, threshold3):\n",
    "    #logits = peak(prediction[0], threshold1) \n",
    "    #logits = peak_tmp(output[0].detach().cpu().numpy(),threshold1,threshold2, threshold3)\n",
    "    \n",
    "    logits = prediction[0][0].cpu().numpy()\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('logits')\n",
    "    plt.imshow(logits)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('logits')\n",
    "    plt.imshow(logits>threshold1)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('peak_tmp')\n",
    "    plt.imshow(peak_tmp(output[0].detach().cpu().numpy(),threshold1, threshold2, threshold3)>threshold1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold1 = -1\n",
    "threshold2 = 1\n",
    "threshold3 = 1\n",
    "predictions = []\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "model.eval()\n",
    "\n",
    "for img, _, _ in tqdm(test_loader):\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(np.einsum('ijk->jki', img[0]))\n",
    "    plt.show()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img.to(device))\n",
    "    output = output[0]['hm']\n",
    "    \n",
    "    show_coords(output,threshold1, threshold2, threshold3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "model.eval()\n",
    "plot = False\n",
    "for img, _, _ in tqdm(test_loader):\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        output = model(img.to(device))\n",
    "    for i in range(output[0]['hm'].shape[0]):\n",
    "        #coords = extract_coords((output[0]['hm'][i], output[0]['reg'][i]),threshold1)\n",
    "        coords = extract_coords_tmp((output[0]['hm'][i], output[0]['reg'][i]),threshold1, threshold2, threshold3)\n",
    "        s = coords2str(coords)\n",
    "        predictions.append(s)\n",
    "        if plot == True:\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            plt.imshow(np.einsum('ijk->jki', img[idx]))\n",
    "            plt.show()\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "test = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "test['PredictionString'] = predictions\n",
    "test.to_csv('./prediction-'+model_name+'_'+str(threshold1)+'_'+str(threshold2)+'_' \\\n",
    "            +str(threshold3)+ '.csv', index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CenterNet",
   "language": "python",
   "name": "centernet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
