{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CenterResnet Starter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am very new to these concepts so I am trying out by changing this amazing and probably only 3D model related awesome public kernel by Ruslan\n",
    "https://www.kaggle.com/hocop1/centernet-baseline\n",
    "\n",
    "Most of the codes are loaned from there . There are other codes that I took from OFT implementation github . But I dont know what is OFT , so I have not yet implemented it . \n",
    "\n",
    "My current score is not from this kernel( as there are some errors in this kernel) , but from some simple architecture modification of the original public kernel. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dohee/anaconda3/envs/CenterNet/lib/python3.6/site-packages/imgaug/imgaug.py:182: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "from tqdm.auto import tqdm as tq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "PATH = '../input/pku-autonomous-driving/'\n",
    "os.listdir(PATH)\n",
    "\n",
    "## Constants\n",
    "SWITCH_LOSS_EPOCH = 5\n",
    "\n",
    "train = pd.read_csv(PATH + 'train.csv')\n",
    "test = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "\n",
    "# From camera.zip\n",
    "camera_matrix = np.array([[2304.5479, 0,  1686.2379],\n",
    "                          [0, 2305.8757, 1354.9849],\n",
    "                          [0, 0, 1]], dtype=np.float32)\n",
    "camera_matrix_inv = np.linalg.inv(camera_matrix)\n",
    "\n",
    "def imread(path, fast_mode=False):\n",
    "    img = cv2.imread(path)\n",
    "    if not fast_mode and img is not None and len(img.shape) == 3:\n",
    "        img = np.array(img[:, :, ::-1])\n",
    "    return img\n",
    "\n",
    "img = imread(PATH + 'train_images/ID_8a6e65317' + '.jpg')\n",
    "IMG_SHAPE = img.shape\n",
    "\n",
    "def str2coords(s, names=['id', 'yaw', 'pitch', 'roll', 'x', 'y', 'z']):\n",
    "    '''\n",
    "    Input:\n",
    "        s: PredictionString (e.g. from train dataframe)\n",
    "        names: array of what to extract from the string\n",
    "    Output:\n",
    "        list of dicts with keys from `names`\n",
    "    '''\n",
    "    coords = []\n",
    "    for l in np.array(s.split()).reshape([-1, 7]):\n",
    "        coords.append(dict(zip(names, l.astype('float'))))\n",
    "        if 'id' in coords[-1]:\n",
    "            coords[-1]['id'] = int(coords[-1]['id'])\n",
    "    return coords\n",
    "\n",
    "def rotate(x, angle):\n",
    "    x = x + angle\n",
    "    x = x - (x + np.pi) // (2 * np.pi) * 2 * np.pi\n",
    "    return x\n",
    "\n",
    "def get_img_coords(s):\n",
    "    '''\n",
    "    Input is a PredictionString (e.g. from train dataframe)\n",
    "    Output is two arrays:\n",
    "        xs: x coordinates in the image\n",
    "        ys: y coordinates in the image\n",
    "    '''\n",
    "    coords = str2coords(s)\n",
    "    xs = [c['x'] for c in coords]\n",
    "    ys = [c['y'] for c in coords]\n",
    "    zs = [c['z'] for c in coords]\n",
    "    P = np.array(list(zip(xs, ys, zs))).T\n",
    "    img_p = np.dot(camera_matrix, P).T\n",
    "    img_p[:, 0] /= img_p[:, 2]\n",
    "    img_p[:, 1] /= img_p[:, 2]\n",
    "    img_xs = img_p[:, 0]\n",
    "    img_ys = img_p[:, 1]\n",
    "    img_zs = img_p[:, 2] # z = Distance from the camera\n",
    "    return img_xs, img_ys\n",
    "\n",
    "from math import sin, cos\n",
    "\n",
    "# convert euler angle to rotation matrix\n",
    "def euler_to_Rot(yaw, pitch, roll):\n",
    "    Y = np.array([[cos(yaw), 0, sin(yaw)],\n",
    "                  [0, 1, 0],\n",
    "                  [-sin(yaw), 0, cos(yaw)]])\n",
    "    P = np.array([[1, 0, 0],\n",
    "                  [0, cos(pitch), -sin(pitch)],\n",
    "                  [0, sin(pitch), cos(pitch)]])\n",
    "    R = np.array([[cos(roll), -sin(roll), 0],\n",
    "                  [sin(roll), cos(roll), 0],\n",
    "                  [0, 0, 1]])\n",
    "    return np.dot(Y, np.dot(P, R))\n",
    "\n",
    "def draw_line(image, points):\n",
    "    color = (255, 0, 0)\n",
    "    cv2.line(image, tuple(points[0][:2]), tuple(points[3][:2]), color, 16)\n",
    "    cv2.line(image, tuple(points[0][:2]), tuple(points[1][:2]), color, 16)\n",
    "    cv2.line(image, tuple(points[1][:2]), tuple(points[2][:2]), color, 16)\n",
    "    cv2.line(image, tuple(points[2][:2]), tuple(points[3][:2]), color, 16)\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_points(image, points):\n",
    "    for (p_x, p_y, p_z) in points:\n",
    "        cv2.circle(image, (p_x, p_y), int(1000 / p_z), (0, 255, 0), -1)\n",
    "#         if p_x > image.shape[1] or p_y > image.shape[0]:\n",
    "#             print('Point', p_x, p_y, 'is out of image with shape', image.shape)\n",
    "    return image\n",
    "\n",
    "def visualize(img, coords):\n",
    "    # You will also need functions from the previous cells\n",
    "    x_l = 1.02\n",
    "    y_l = 0.80\n",
    "    z_l = 2.31\n",
    "    \n",
    "    img = img.copy()\n",
    "    for point in coords:\n",
    "        # Get values\n",
    "        x, y, z = point['x'], point['y'], point['z']\n",
    "        yaw, pitch, roll = -point['pitch'], -point['yaw'], -point['roll']\n",
    "        # Math\n",
    "        Rt = np.eye(4)\n",
    "        t = np.array([x, y, z])\n",
    "        Rt[:3, 3] = t\n",
    "        Rt[:3, :3] = euler_to_Rot(yaw, pitch, roll).T\n",
    "        Rt = Rt[:3, :]\n",
    "        P = np.array([[x_l, -y_l, -z_l, 1],\n",
    "                      [x_l, -y_l, z_l, 1],\n",
    "                      [-x_l, -y_l, z_l, 1],\n",
    "                      [-x_l, -y_l, -z_l, 1],\n",
    "                      [0, 0, 0, 1]]).T\n",
    "        img_cor_points = np.dot(camera_matrix, np.dot(Rt, P))\n",
    "        img_cor_points = img_cor_points.T\n",
    "        img_cor_points[:, 0] /= img_cor_points[:, 2]\n",
    "        img_cor_points[:, 1] /= img_cor_points[:, 2]\n",
    "        img_cor_points = img_cor_points.astype(int)\n",
    "        # Drawing\n",
    "        img = draw_line(img, img_cor_points)\n",
    "        img = draw_points(img, img_cor_points[-1:])\n",
    "    \n",
    "    return img\n",
    "\n",
    "IMG_WIDTH = 2048\n",
    "IMG_HEIGHT = IMG_WIDTH // 4\n",
    "MODEL_SCALE = 8\n",
    "\n",
    "def _regr_preprocess(regr_dict):\n",
    "    for name in ['x', 'y', 'z']:\n",
    "        regr_dict[name] = regr_dict[name] / 100\n",
    "    regr_dict['roll'] = rotate(regr_dict['roll'], np.pi)\n",
    "    regr_dict['pitch_sin'] = sin(regr_dict['pitch'])\n",
    "    regr_dict['pitch_cos'] = cos(regr_dict['pitch'])\n",
    "    regr_dict.pop('pitch')\n",
    "    regr_dict.pop('id')\n",
    "    return regr_dict\n",
    "\n",
    "def _regr_back(regr_dict):\n",
    "    for name in ['x', 'y', 'z']:\n",
    "        regr_dict[name] = regr_dict[name] * 100\n",
    "    regr_dict['roll'] = rotate(regr_dict['roll'], -np.pi)\n",
    "    \n",
    "    pitch_sin = regr_dict['pitch_sin'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
    "    pitch_cos = regr_dict['pitch_cos'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
    "    regr_dict['pitch'] = np.arccos(pitch_cos) * np.sign(pitch_sin)\n",
    "    return regr_dict\n",
    "\n",
    "def preprocess_image(img):\n",
    "    img = img[img.shape[0] //2 :]\n",
    "    bg = np.ones_like(img) * img.mean(1, keepdims=True).astype(img.dtype)\n",
    "    bg = bg[:, :img.shape[1] // 4]\n",
    "    img = np.concatenate([bg, img, bg], 1)\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    return (img / 255).astype('float32')\n",
    "\n",
    "def get_mask_and_regr(img, labels):\n",
    "    mask = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n",
    "    regr_names = ['x', 'y', 'z', 'yaw', 'pitch', 'roll']\n",
    "    regr = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 7], dtype='float32')\n",
    "    coords = str2coords(labels)\n",
    "    xs, ys = get_img_coords(labels)\n",
    "    for x, y, regr_dict in zip(xs, ys, coords):\n",
    "        x, y = y, x\n",
    "        x = (x - img.shape[0] // 2) * IMG_HEIGHT / (img.shape[0] // 2) / MODEL_SCALE\n",
    "        x = np.round(x).astype('int')\n",
    "        y = (y + img.shape[1] // 4) * IMG_WIDTH / (img.shape[1] * 1.5) / MODEL_SCALE\n",
    "        y = np.round(y).astype('int')\n",
    "        if x >= 0 and x < IMG_HEIGHT // MODEL_SCALE and y >= 0 and y < IMG_WIDTH // MODEL_SCALE:\n",
    "            mask[x, y] = 1\n",
    "            regr_dict = _regr_preprocess(regr_dict)\n",
    "            regr[x, y] = [regr_dict[n] for n in sorted(regr_dict)]\n",
    "    return mask, regr\n",
    "\n",
    "class CarDataset(Dataset):\n",
    "    \"\"\"Car dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, root_dir, training=True, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Get image name\n",
    "        idx, labels = self.df.values[idx]\n",
    "        img_name = self.root_dir.format(idx)\n",
    "        \n",
    "        # Read image\n",
    "        img0 = imread(img_name, True)\n",
    "        img = preprocess_image(img0)\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "        \n",
    "        # Get mask and regression maps\n",
    "        if self.training:\n",
    "            mask, regr = get_mask_and_regr(img0, labels)\n",
    "            regr = np.rollaxis(regr, 2, 0)\n",
    "        else:\n",
    "            mask, regr = 0, 0\n",
    "        \n",
    "        return [img, mask, regr]\n",
    "    \n",
    "train_images_dir = PATH + 'train_images/{}.jpg'\n",
    "test_images_dir = PATH + 'test_images/{}.jpg'\n",
    "\n",
    "df_train, df_dev = train_test_split(train, test_size=0.01, random_state=42)\n",
    "df_test = test\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "        iaa.Add((-10, 10), per_channel=0.5),\n",
    "        iaa.ContrastNormalization((0.75, 1.5)),\n",
    "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    ])\n",
    "      \n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        return self.aug.augment_image(img)\n",
    "\n",
    "transforms = ImgAugTransform()\n",
    "\n",
    "train_dataset = CarDataset(df_train, train_images_dir, transform = transforms)\n",
    "dev_dataset = CarDataset(df_dev, train_images_dir)\n",
    "test_dataset = CarDataset(df_test, test_images_dir)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Create data generators - they will produce batches\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from dlav0 import get_pose_net as get_dlav0\n",
    "\n",
    "_model_factory = {\n",
    "  #'res': get_pose_net, # default Resnet with deconv\n",
    "  'dlav0': get_dlav0, # default DLAup\n",
    "  #'dla': get_dla_dcn,\n",
    "  #'resdcn': get_pose_net_dcn,\n",
    "  #'hourglass': get_large_hourglass_net,\n",
    "}\n",
    "\n",
    "def create_model(arch, heads, head_conv):\n",
    "    num_layers = int(arch[arch.find('_') + 1:]) if '_' in arch else 0\n",
    "    arch = arch[:arch.find('_')] if '_' in arch else arch\n",
    "    arch = 'dlav0'\n",
    "    get_model = _model_factory[arch]\n",
    "    model = get_model(num_layers=num_layers, heads=heads, head_conv=head_conv)\n",
    "    return model\n",
    "\n",
    "model = create_model('dla_34', {'hm': 1, 'reg' : 7} , 256)\n",
    "\n",
    "# Gets the GPU if there is one, otherwise the cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "#model = CentResnet(8).to(device)\n",
    "model.cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=8 * len(train_loader), gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_radius(det_size, min_overlap=0.7):\n",
    "    height, width = det_size\n",
    "\n",
    "    a1  = 1\n",
    "    b1  = (height + width)\n",
    "    c1  = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "    sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "    r1  = (b1 + sq1) / 2\n",
    "\n",
    "    a2  = 4\n",
    "    b2  = 2 * (height + width)\n",
    "    c2  = (1 - min_overlap) * width * height\n",
    "    sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "    r2  = (b2 + sq2) / 2\n",
    "\n",
    "    a3  = 4 * min_overlap\n",
    "    b3  = -2 * min_overlap * (height + width)\n",
    "    c3  = (min_overlap - 1) * width * height\n",
    "    sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "    r3  = (b3 + sq3) / 2\n",
    "    return min(r1, r2, r3)\n",
    "\n",
    "def gaussian2D(shape, sigma=1):\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m+1,-n:n+1]\n",
    "\n",
    "    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    return h\n",
    "\n",
    "def draw_msra_gaussian(heatmap, center, sigma):\n",
    "    tmp_size = sigma * 3\n",
    "    mu_x = int(center[0] + 0.5)\n",
    "    mu_y = int(center[1] + 0.5)\n",
    "    w, h = heatmap.shape[0], heatmap.shape[1]\n",
    "    ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
    "    br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
    "    if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
    "        return heatmap\n",
    "    size = 2 * tmp_size + 1\n",
    "    x = np.arange(0, size, 1, np.float32)\n",
    "    y = x[:, np.newaxis]\n",
    "    \n",
    "    x0 = y0 = size // 2\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
    "    g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
    "    img_x = max(0, ul[0]), min(br[0], h)\n",
    "    img_y = max(0, ul[1]), min(br[1], w)\n",
    "    \n",
    "    \n",
    "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
    "        heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
    "        g[g_y[0]:g_y[1], g_x[0]:g_x[1]])\n",
    "    return heatmap\n",
    "\n",
    "def gaussian_mask(mask):\n",
    "    xlist, ylist = np.where(mask == 1)\n",
    "    masklist = [(i,j) for i, j in zip(xlist, ylist)]\n",
    "    hm = np.zeros(mask.shape) \n",
    "\n",
    "    for (y,x) in masklist:\n",
    "        bbox = np.array([x-1, y-1, x+1, y+1])\n",
    "        h, w = bbox[3] - bbox[1], bbox[2] - bbox[0]\n",
    "        radius = gaussian_radius((h, w))    \n",
    "        ct = np.array([x,y], dtype=np.float32)\n",
    "        ct_int = ct.astype(np.int32)\n",
    "        #hm[int(bbox[1]): int(bbox[3]), int(bbox[0]): int(bbox[2])] = 0.9999    \n",
    "        hm = draw_msra_gaussian(hm, ct, radius) # np.exp((y-5)/200)\n",
    "    \n",
    "    return hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x2304 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(32,32))\n",
    "plt.imshow(gaussian_mask(train_dataset[2][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def _neg_loss(pred, gt):\n",
    "    ''' Modified focal loss. Exactly the same as CornerNet.\n",
    "      Runs faster and costs a little bit more memory\n",
    "    Arguments:\n",
    "      pred (batch x c x h x w)\n",
    "      gt_regr (batch x c x h x w)\n",
    "    '''\n",
    "    \n",
    "    for i in range(gt.shape[0]):\n",
    "        gt[i] = torch.from_numpy(gaussian_mask(gt[i].cpu()))\n",
    "    \n",
    "    pos_inds = gt.eq(1).float()\n",
    "    neg_inds = gt.lt(1).float()\n",
    "\n",
    "    neg_weights = torch.pow(1 - gt, 4)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    pos_loss = torch.log(pred) * torch.pow(1 - pred, 2) * pos_inds\n",
    "    neg_loss = torch.log(1 - pred) * torch.pow(pred, 2) * neg_weights * neg_inds\n",
    "\n",
    "    num_pos  = pos_inds.float().sum()\n",
    "    pos_loss = pos_loss.sum()\n",
    "    neg_loss = neg_loss.sum()\n",
    "\n",
    "    if num_pos == 0:\n",
    "        loss = loss - neg_loss\n",
    "    else:\n",
    "        loss = loss - (pos_loss + neg_loss) / num_pos\n",
    "    return loss\n",
    "\n",
    "def criterion(prediction, mask, regr, weight=0.8, size_average=True):\n",
    "\n",
    "    # Binary mask loss\n",
    "    pred_mask = prediction[0]['hm']\n",
    "    pred_mask = torch.sigmoid(pred_mask[:, 0])\n",
    "#     mask_loss = mask * (1 - pred_mask)**2 * torch.log(pred_mask + 1e-12) + (1 - mask) * pred_mask**2 * torch.log(1 - pred_mask + 1e-12)\n",
    "\n",
    "    #mask_loss = mask * torch.log(pred_mask + 1e-12) + (1 - mask) * torch.log(1 - pred_mask + 1e-12)\n",
    "    #mask_loss = -mask_loss.mean(0).sum()\n",
    "    \n",
    "    mask_loss = _neg_loss(pred_mask,mask)\n",
    "    \n",
    "    # Regression L1 loss\n",
    "    #pred_regr = prediction[:, 1:]\n",
    "    pred_regr = prediction[0]['reg']\n",
    "    #regr_loss = (torch.abs(pred_regr - regr).sum(1) * mask).sum(1).sum(1) / mask.sum(1).sum(1\n",
    "    \n",
    "    #for i in range(regr.shape[0]):\n",
    "    #    for j in range(regr.shape[1]):\n",
    "    #        regr[i][j] = torch.from_numpy(gaussian_mask_reg(regr[i][j].cpu()))\n",
    "\n",
    "    regr_loss = (torch.min(torch.abs(pred_regr - regr), torch.abs((pred_regr - regr)**2)).sum(1) * mask).sum(1).sum(1) / mask.sum(1).sum(1)\n",
    "    # smooth l1 - torch.min(torch.abs(pred_regr - regr), torch.abs((pred_regr - regr)**2))\n",
    "    regr_loss = regr_loss.mean(0)\n",
    "\n",
    "    # Sum\n",
    "    loss = weight*mask_loss +(1-weight)* regr_loss\n",
    "    #if not size_average:\n",
    "    #    loss *= prediction.shape[0]\n",
    "    return loss ,mask_loss , regr_loss\n",
    "\n",
    "def train(epoch, history=None):\n",
    "    model.train()\n",
    "    t = tqdm(train_loader)\n",
    "    for batch_idx, (img_batch, mask_batch, regr_batch) in enumerate(t):\n",
    "        img_batch = img_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "        regr_batch = regr_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(img_batch)\n",
    "        \n",
    "        if epoch < SWITCH_LOSS_EPOCH :\n",
    "            loss, mask_loss, regr_loss = criterion(output, mask_batch, regr_batch,1)\n",
    "        else:\n",
    "            loss,mask_loss, regr_loss = criterion(output, mask_batch, regr_batch,0.5)  \n",
    "        \n",
    "        t.set_description(f'train_loss (l={loss:.3f})(m={mask_loss:.2f}) (r={regr_loss:.4f}')\n",
    "        \n",
    "        if history is not None:\n",
    "            history.loc[epoch + batch_idx / len(train_loader), 'train_loss'] = loss.data.cpu().numpy()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        exp_lr_scheduler.step()\n",
    "\n",
    "    \n",
    "    print('Train Epoch: {} \\tLR: {:.6f}\\tLoss: {:.6f}\\tMaskLoss: {:.6f}\\tRegLoss: {:.6f}'.format(\n",
    "        epoch,\n",
    "        optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "        loss.data,\n",
    "        mask_loss.data,\n",
    "        regr_loss.data))\n",
    "\n",
    "def evaluate(epoch, history=None):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    valid_loss = 0\n",
    "    valid_mask_loss = 0\n",
    "    valid_regr_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for img_batch, mask_batch, regr_batch in dev_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            mask_batch = mask_batch.to(device)\n",
    "            regr_batch = regr_batch.to(device)\n",
    "\n",
    "            output = model(img_batch)\n",
    "\n",
    "            if epoch < SWITCH_LOSS_EPOCH :\n",
    "                loss,mask_loss, regr_loss= criterion(output, mask_batch, regr_batch,1, size_average=False)\n",
    "                valid_loss += loss.data\n",
    "                valid_mask_loss += mask_loss.data\n",
    "                valid_regr_loss += regr_loss.data\n",
    "            else :\n",
    "                loss,mask_loss, regr_loss = criterion(output, mask_batch, regr_batch,0.5, size_average=False)\n",
    "                valid_loss += loss.data\n",
    "                valid_mask_loss += mask_loss.data\n",
    "                valid_regr_loss += regr_loss.data \n",
    "\n",
    "    \n",
    "    valid_loss /= len(dev_loader.dataset)\n",
    "    valid_mask_loss /= len(dev_loader.dataset)\n",
    "    valid_regr_loss /= len(dev_loader.dataset)\n",
    "    \n",
    "    if history is not None:\n",
    "        history.loc[epoch, 'dev_loss'] = valid_loss.cpu().numpy()\n",
    "        history.loc[epoch, 'mask_loss'] = valid_mask_loss.cpu().numpy()\n",
    "        history.loc[epoch, 'regr_loss'] = valid_regr_loss.cpu().numpy()\n",
    "\n",
    "    \n",
    "    print('Dev loss: {:.4f}'.format(valid_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dohee/anaconda3/envs/CenterNet/lib/python3.6/site-packages/ipykernel_launcher.py:67: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a87bd5683d34648a6ef2170b7bbf7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1055.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "history = pd.DataFrame()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    train(epoch, history)\n",
    "    evaluate(epoch, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dla34'\n",
    "torch.save(model.state_dict(), './model-'+'_'+model_name+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['train_loss'].iloc[100:].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = history.dropna()['mask_loss']\n",
    "plt.plot(series1.index, series1 ,label = 'mask loss');\n",
    "series2 = history.dropna()['regr_loss']\n",
    "plt.plot(series2.index, 30*series2,label = 'regr loss');\n",
    "series3 = history.dropna()['dev_loss']\n",
    "plt.plot(series3.index, series3,label = 'dev loss', color = 'red');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = history.dropna()['dev_loss']\n",
    "plt.scatter(series.index, series);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load( './model-dla34'+'_'+'w08'+'.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10,20):\n",
    "    img, mask, regr = dev_dataset[i]\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Input image')\n",
    "    plt.imshow(np.rollaxis(img, 0, 3))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Ground truth mask')\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "\n",
    "    output = model(torch.tensor(img[None]).to(device))\n",
    "    logits = output[0]['hm'].data.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Model predictions')\n",
    "    plt.imshow(logits[0,0])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Model predictions thresholded')\n",
    "    plt.imshow(logits[0,0] > -1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_THRESH_CLEAR = 2\n",
    "\n",
    "def convert_3d_to_2d(x, y, z, fx = 2304.5479, fy = 2305.8757, cx = 1686.2379, cy = 1354.9849):\n",
    "    # stolen from https://www.kaggle.com/theshockwaverider/eda-visualization-baseline\n",
    "    return x * fx / z + cx, y * fy / z + cy\n",
    "\n",
    "def optimize_xy(r, c, x0, y0, z0):\n",
    "    def distance_fn(xyz):\n",
    "        x, y, z = xyz\n",
    "        x, y = convert_3d_to_2d(x, y, z0)\n",
    "        y, x = x, y\n",
    "        x = (x - IMG_SHAPE[0] // 2) * IMG_HEIGHT / (IMG_SHAPE[0] // 2) / MODEL_SCALE\n",
    "        x = np.round(x).astype('int')\n",
    "        y = (y + IMG_SHAPE[1] // 4) * IMG_WIDTH / (IMG_SHAPE[1] * 1.5) / MODEL_SCALE\n",
    "        y = np.round(y).astype('int')\n",
    "        return (x-r)**2 + (y-c)**2\n",
    "    \n",
    "    res = minimize(distance_fn, [x0, y0, z0], method='Powell')\n",
    "    x_new, y_new, z_new = res.x\n",
    "    return x_new, y_new, z0\n",
    "\n",
    "def clear_duplicates(coords):\n",
    "    for c1 in coords:\n",
    "        xyz1 = np.array([c1['x'], c1['y'], c1['z']])\n",
    "        for c2 in coords:\n",
    "            xyz2 = np.array([c2['x'], c2['y'], c2['z']])\n",
    "            distance = np.sqrt(((xyz1 - xyz2)**2).sum())\n",
    "            if distance < DISTANCE_THRESH_CLEAR:\n",
    "                if c1['confidence'] < c2['confidence']:\n",
    "                    c1['confidence'] = -1\n",
    "    return [c for c in coords if c['confidence'] > 0]\n",
    "\n",
    "def coords2str(coords, names=['yaw', 'pitch', 'roll', 'x', 'y', 'z', 'confidence']):\n",
    "    s = []\n",
    "    for c in coords:\n",
    "        for n in names:\n",
    "            s.append(str(c.get(n, 0)))\n",
    "    return ' '.join(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from math import sqrt, acos, pi, sin, cos\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from inspect import signature\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def expand_df(df, PredictionStringCols):\n",
    "    df = df.dropna().copy()\n",
    "    df['NumCars'] = [int((x.count(' ')+1)/7) for x in df['PredictionString']]\n",
    "\n",
    "    image_id_expanded = [item for item, count in zip(df['ImageId'], df['NumCars']) for i in range(count)]\n",
    "    prediction_strings_expanded = df['PredictionString'].str.split(' ',expand = True).values.reshape(-1,7).astype(float)\n",
    "    prediction_strings_expanded = prediction_strings_expanded[~np.isnan(prediction_strings_expanded).all(axis=1)]\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'ImageId': image_id_expanded,\n",
    "            PredictionStringCols[0]:prediction_strings_expanded[:,0],\n",
    "            PredictionStringCols[1]:prediction_strings_expanded[:,1],\n",
    "            PredictionStringCols[2]:prediction_strings_expanded[:,2],\n",
    "            PredictionStringCols[3]:prediction_strings_expanded[:,3],\n",
    "            PredictionStringCols[4]:prediction_strings_expanded[:,4],\n",
    "            PredictionStringCols[5]:prediction_strings_expanded[:,5],\n",
    "            PredictionStringCols[6]:prediction_strings_expanded[:,6]\n",
    "        })\n",
    "    return df\n",
    "\n",
    "def TranslationDistance(p,g, abs_dist = False):\n",
    "    dx = p['x'] - g['x']\n",
    "    dy = p['y'] - g['y']\n",
    "    dz = p['z'] - g['z']\n",
    "    diff0 = (g['x']**2 + g['y']**2 + g['z']**2)**0.5\n",
    "    diff1 = (dx**2 + dy**2 + dz**2)**0.5\n",
    "    if abs_dist:\n",
    "        diff = diff1\n",
    "    else:\n",
    "        diff = diff1/diff0\n",
    "    return diff\n",
    "\n",
    "def RotationDistance(p, g):\n",
    "    true=[ g['pitch'] ,g['yaw'] ,g['roll'] ]\n",
    "    pred=[ p['pitch'] ,p['yaw'] ,p['roll'] ]\n",
    "    q1 = R.from_euler('xyz', true)\n",
    "    q2 = R.from_euler('xyz', pred)\n",
    "    diff = R.inv(q2) * q1\n",
    "    W = np.clip(diff.as_quat()[-1], -1., 1.)\n",
    "    \n",
    "    # in the official metrics code:\n",
    "    # https://www.kaggle.com/c/pku-autonomous-driving/overview/evaluation\n",
    "    #   return Object3D.RadianToDegree( Math.Acos(diff.W) )\n",
    "    # this code treat θ and θ+2π differntly.\n",
    "    # So this should be fixed as follows.\n",
    "    W = (acos(W)*360)/pi\n",
    "    if W > 180:\n",
    "        W = 360 - W\n",
    "    return W\n",
    "\n",
    "def print_pr_curve(result_flg, scores, recall_total=1):\n",
    "    average_precision = average_precision_score(result_flg, scores)\n",
    "    precision, recall, _ = precision_recall_curve(result_flg, scores)\n",
    "    recall *= recall_total\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_tr_list = [0.1, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01]\n",
    "thres_ro_list = [50, 45, 40, 35, 30, 25, 20, 15, 10, 5]\n",
    "\n",
    "def check_match(idx):\n",
    "    keep_gt=False\n",
    "    thre_tr_dist = thres_tr_list[idx]\n",
    "    thre_ro_dist = thres_ro_list[idx]\n",
    "    train_dict = {imgID:str2coords(s, names=['carid_or_score', 'pitch', 'yaw', 'roll', 'x', 'y', 'z']) for imgID,s in zip(train_df['ImageId'],train_df['PredictionString'])}\n",
    "    valid_dict = {imgID:str2coords(s, names=['pitch', 'yaw', 'roll', 'x', 'y', 'z', 'carid_or_score']) for imgID,s in zip(valid_df['ImageId'],valid_df['PredictionString'])}\n",
    "    result_flg = [] # 1 for TP, 0 for FP\n",
    "    scores = []\n",
    "    MAX_VAL = 10**10\n",
    "    for img_id in valid_dict:\n",
    "        for pcar in sorted(valid_dict[img_id], key=lambda x: -x['carid_or_score']):\n",
    "            # find nearest GT\n",
    "            min_tr_dist = MAX_VAL\n",
    "            min_idx = -1\n",
    "            for idx, gcar in enumerate(train_dict[img_id]):\n",
    "                tr_dist = TranslationDistance(pcar,gcar)\n",
    "                if tr_dist < min_tr_dist:\n",
    "                    min_tr_dist = tr_dist\n",
    "                    min_ro_dist = RotationDistance(pcar,gcar)\n",
    "                    min_idx = idx\n",
    "                    \n",
    "            # set the result\n",
    "            if min_tr_dist < thre_tr_dist and min_ro_dist < thre_ro_dist:\n",
    "                if not keep_gt:\n",
    "                    train_dict[img_id].pop(min_idx)\n",
    "                result_flg.append(1)\n",
    "            else:\n",
    "                result_flg.append(0)\n",
    "            scores.append(pcar['carid_or_score'])\n",
    "    \n",
    "    return result_flg, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = -1\n",
    "threshold2 = 1\n",
    "threshold3 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coords(prediction, threshold1):\n",
    "    \n",
    "    img = prediction[0][0].cpu().numpy()\n",
    "    #logits = prediction[0][0].cpu().numpy()\n",
    "    logits = peak_tmp(prediction[0].cpu().numpy(), threshold1, threshold2, threshold3)\n",
    "    \n",
    "    regr_output = prediction[1].cpu().numpy()\n",
    "    points = np.argwhere(logits > threshold1)\n",
    "\n",
    "    # top 100 points\n",
    "    (xlist, ylist) =  np.where(img>np.sort(img.reshape((1,-1)))[0][-100])\n",
    "    top_list = [pair for pair in zip(list(xlist), list(ylist))]\n",
    "    \n",
    "    col_names = sorted(['x', 'y', 'z', 'yaw', 'pitch_sin', 'pitch_cos', 'roll'])\n",
    "    coords = []\n",
    "    \n",
    "    for r, c in points:\n",
    "        if (r,c) not in top_list:\n",
    "            continue\n",
    "            \n",
    "        regr_dict = dict(zip(col_names, regr_output[:, r, c]))\n",
    "        coords.append(_regr_back(regr_dict))\n",
    "        coords[-1]['confidence'] = 1 / (1 + np.exp(-logits[r, c]))\n",
    "        coords[-1]['x'], coords[-1]['y'], coords[-1]['z'] = optimize_xy(r, c, coords[-1]['x'], coords[-1]['y'], coords[-1]['z'])\n",
    "    coords = clear_duplicates(coords)\n",
    "    return coords\n",
    "\n",
    "def extract_coords_tmp(prediction, threshold1, threshold2, threshold3):\n",
    "    \n",
    "    img = prediction[0][0].cpu().numpy()\n",
    "    logits = peak_tmp(prediction[0].cpu().numpy(), threshold1, threshold2, threshold3)\n",
    "    #logits = prediction[0][0].cpu().numpy()\n",
    "    plt.title(\"logits\")\n",
    "    plt.imshow(logits>-2)\n",
    "    plt.show()\n",
    "    \n",
    "    regr_output = prediction[1].cpu().numpy()\n",
    "    points = np.argwhere(logits > threshold1)\n",
    "\n",
    "    # top 100 points\n",
    "    (xlist, ylist) =  np.where(img>np.sort(img.reshape((1,-1)))[0][-100])\n",
    "    top_list = [pair for pair in zip(list(xlist), list(ylist))]\n",
    "    \n",
    "    col_names = sorted(['x', 'y', 'z', 'yaw', 'pitch_sin', 'pitch_cos', 'roll'])\n",
    "    coords = []\n",
    "    \n",
    "    for r, c in points:\n",
    "        if (r,c) not in top_list:\n",
    "            continue\n",
    "            \n",
    "        regr_dict = dict(zip(col_names, regr_output[:, r, c]))\n",
    "        coords.append(_regr_back(regr_dict))\n",
    "        coords[-1]['confidence'] = 1 / (1 + np.exp(-logits[r, c]))\n",
    "        coords[-1]['x'], coords[-1]['y'], coords[-1]['z'] = optimize_xy(r, c, coords[-1]['x'], coords[-1]['y'], coords[-1]['z'])\n",
    "    coords = clear_duplicates(coords)\n",
    "    return coords\n",
    "\n",
    "def peak_tmp(array, threshold1, threshold2, threshold3):\n",
    "    (xlist, ylist) = np.where(array[0]>np.sort(array[0].reshape((1,-1)))[0][-100])\n",
    "    \n",
    "    peak_array = array[0]\n",
    "    maximum = array.max()\n",
    "    threshold_iter = 0\n",
    "    \n",
    "    while np.sum(peak_array>threshold1)<5 and threshold_iter<8:\n",
    "        threshold_iter+=1\n",
    "        peak_array += 0.5\n",
    "        print(\"brighter:\", np.sum(peak_array>threshold1))\n",
    "    \n",
    "    advantage = np.zeros(array[0].shape)\n",
    "    penalty = np.zeros(array[0].shape)\n",
    "    \n",
    "    for k in range(len(xlist)):\n",
    "        i = xlist[k]\n",
    "        j = ylist[k]\n",
    "        ct1 = 0 # 주변의 점들이 top 100 안에 있는가\n",
    "        ct2 = 0 # 주변의 점들의 값이 더 작은가 \n",
    "        \n",
    "        if 0<i<array.shape[1]-1 and 0<j<array.shape[2]-1:    \n",
    "            surroundings = [(i-1,j+1),(i-1,j),(i-1,j+1),(i,j-1),(i,j+1),(i+1,j+1),(i+1,j),(i+1,j+1)]\n",
    "            for xy in surroundings:\n",
    "                if (xy[0], xy[1]) in list(zip(xlist, ylist)):                    \n",
    "                    ct1 += 1\n",
    "                if peak_array[i,j] > peak_array[xy[0], xy[1]]:\n",
    "                    ct2 += 1\n",
    "            if ct1 > 6 and ct2 > 7:\n",
    "                advantage[i,j] += min((maximum - peak_array[i,j])*(1/2),2)\n",
    "                \n",
    "    peak_array = peak_array + advantage*threshold2\n",
    "    \n",
    "    \n",
    "    for i in range(1,array.shape[1]-1):\n",
    "        for j in range(1,array.shape[2]-1):    \n",
    "            ct_sur = 0\n",
    "            ct_vert = 0\n",
    "            ct_hori = 0\n",
    "            surroundings = [(i,j),(i,j+1),(i+1,j),(i+1,j+1)]\n",
    "            horizontal = [(i,j-1),(i,j),(i,j+1)]\n",
    "            vertical = [(i-1,j),(i,j),(i+1,j)] \n",
    "            \n",
    "            for xy in surroundings:\n",
    "                if array[0][xy[0],xy[1]]>threshold1:\n",
    "                    ct_sur += 1\n",
    "                    \n",
    "            for xy in vertical:\n",
    "                if array[0][xy[0],xy[1]]>threshold1:\n",
    "                    ct_vert += 1\n",
    "\n",
    "            for xy in vertical:\n",
    "                if array[0][xy[0],xy[1]]>threshold1:\n",
    "                    ct_hori += 1\n",
    "\n",
    "            if ct_sur > 2:\n",
    "                idx_small = np.array([array[0][i,j],array[0][i,j+1],array[0][i+1,j],array[0][i+1,j+1]]).argsort()[:2]\n",
    "                idx_list = [[i,j],[i,j+1],[i+1,j],[i+1,j+1]]\n",
    "                for i in idx_small:\n",
    "                    penalty[idx_list[i][0], idx_list[i][1]] -= 1\n",
    "\n",
    "            if ct_vert == 3:\n",
    "                idx_small = np.array([array[0][i-1,j],array[0][i,j],array[0][i+1,j]]).argsort()[:2]\n",
    "                idx_list = [[i-1,j],[i,j],[i+1,j]]\n",
    "                for i in idx_small:\n",
    "                    penalty[idx_list[i][0], idx_list[i][1]] -= 1\n",
    "\n",
    "            if ct_hori == 3:\n",
    "                idx_small = np.array([array[0][i-1,j],array[0][i,j],array[0][i+1,j]]).argsort()[:1]\n",
    "                idx_list = [[i,j-1],[i,j],[i,j+1]]\n",
    "                for i in idx_small:\n",
    "                    penalty[idx_list[i][0], idx_list[i][1]] -= 1\n",
    "\n",
    "    #print(\"advantage:\", np.sum(advantage)*threshold2)\n",
    "    #print(\"penalty:\", np.sum(penalty)*threshold3)\n",
    "    \n",
    "    \n",
    "    peak_array = peak_array + penalty*threshold3\n",
    "    \n",
    "    return peak_array #, advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "predictions = []\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "model.eval()\n",
    "for img, _, _ in tqdm(dev_loader):\n",
    "    with torch.no_grad():\n",
    "        output = model(img.to(device))\n",
    "    \n",
    "    for i in range(output[0]['hm'].shape[0]):\n",
    "        coords = extract_coords((output[0]['hm'][i], output[0]['reg'][i]),0)\n",
    "        s = coords2str(coords)\n",
    "        predictions.append(s)\n",
    "        \n",
    "df_dev['PredictionString'] = copy.copy(predictions)\n",
    "\n",
    "valid_df = df_dev\n",
    "expanded_valid_df = expand_df(valid_df, ['pitch','yaw','roll','x','y','z','Score'])\n",
    "valid_df = valid_df.fillna('')\n",
    "\n",
    "train_df = pd.read_csv('../input/pku-autonomous-driving/train.csv')\n",
    "train_df = train_df[train_df.ImageId.isin(valid_df.ImageId.unique())]\n",
    "# data description page says, The pose information is formatted as\n",
    "# model type, yaw, pitch, roll, x, y, z\n",
    "# but it doesn't, and it should be\n",
    "# model type, pitch, yaw, roll, x, y, z\n",
    "expanded_train_df = expand_df(train_df, ['model_type','pitch','yaw','roll','x','y','z'])\n",
    "\n",
    "max_workers = 10\n",
    "n_gt = len(expanded_train_df)\n",
    "ap_list = []\n",
    "p = Pool(processes=max_workers)\n",
    "for result_flg, scores in p.imap(check_match, range(10)):\n",
    "    if np.sum(result_flg) > 0:\n",
    "        n_tp = np.sum(result_flg)\n",
    "        recall = n_tp/n_gt\n",
    "        ap = average_precision_score(result_flg, scores)*recall\n",
    "        print_pr_curve(result_flg, scores, recall)\n",
    "    else:\n",
    "        ap = 0\n",
    "    ap_list.append(ap)\n",
    "map = np.mean(ap_list)\n",
    "print('map:', map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = 0\n",
    "threshold2 = 1\n",
    "threshold3 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(40,50):\n",
    "    img, mask, regr = train_dataset[i]\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Input image')\n",
    "    plt.imshow(np.rollaxis(img, 0, 3))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Ground truth mask')\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "    \n",
    "    output = model(torch.tensor(img[None]).to(device))\n",
    "    output = output[0]['hm']\n",
    "    logits = output[0,0].data.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Model predictions')\n",
    "    plt.imshow(logits)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('Model predictions thresholded')\n",
    "    plt.imshow(logits>-1)\n",
    "    plt.show()\n",
    "    \n",
    "    img = peak_tmp(output[0].detach().cpu().numpy(),threshold1,threshold2,threshold3)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title('peak')\n",
    "    plt.imshow(img>threshold1)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_coords(prediction, threshold1, threshold2, threshold3):\n",
    "    #logits = peak(prediction[0], threshold1) \n",
    "    logits = prediction[0][0].cpu().numpy()\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('original')\n",
    "    plt.imshow(logits>threshold1)\n",
    "    plt.show()\n",
    "    \n",
    "    logits = peak_tmp(output[0].detach().cpu().numpy(),threshold1,threshold2, threshold3)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('logits')\n",
    "    plt.imshow(logits)\n",
    "    plt.show()\n",
    "\n",
    "    #plt.figure(figsize=(12, 8))\n",
    "    #plt.title('Prediction')\n",
    "    #plt.imshow(peak_tmp(output[0].detach().cpu().numpy(),threshold1, threshold2, threshold3)>-1)\n",
    "    #plt.show()\n",
    "\n",
    "    regr_output = prediction[1:]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(logits > threshold1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# threshold1 = -1\n",
    "# threshold2 = 1\n",
    "# threshold3 = 1\n",
    "# predictions = []\n",
    "\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "# model.eval()\n",
    "\n",
    "# for img, _, _ in tqdm(test_loader):\n",
    "    \n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     plt.title('Original Image')\n",
    "#     plt.imshow(np.einsum('ijk->jki', img[0]))\n",
    "#     plt.show()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         output = model(img.to(device))\n",
    "#     output = output[0]['hm']\n",
    "    \n",
    "#     show_coords(output,threshold1, threshold2, threshold3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "model.eval()\n",
    "plot = False\n",
    "for img, _, _ in tqdm(test_loader):\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        output = model(img.to(device))\n",
    "    for i in range(output[0]['hm'].shape[0]):\n",
    "        #coords = extract_coords((output[0]['hm'][i], output[0]['reg'][i]),threshold1)\n",
    "        coords = extract_coords_tmp((output[0]['hm'][i], output[0]['reg'][i]),threshold1, threshold2, threshold3)\n",
    "        s = coords2str(coords)\n",
    "        predictions.append(s)\n",
    "        if plot == True:\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            plt.imshow(np.einsum('ijk->jki', img[idx]))\n",
    "            plt.show()\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "test = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "test['PredictionString'] = predictions\n",
    "test.to_csv('./prediction-'+model_name+'_'+str(threshold1)+'_'+str(threshold2)+'_' \\\n",
    "            +str(threshold3)+ '.csv', index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CenterNet",
   "language": "python",
   "name": "centernet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
